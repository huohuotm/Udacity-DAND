{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/weidian1/Documents/GitHub/Udacity-DAND/P5-Intro to ML/Project5/final_project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weidian1/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "#sys.path.append(\"../pylof-master/\")\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "\n",
    "### Task 1: Select what features you'll use.\n",
    "### features_list is a list of strings, each of which is a feature name.\n",
    "### The first feature must be \"poi\".\n",
    "#features_list = ['poi','salary',''] # You will need to use more features\n",
    "\n",
    "### Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of data points:  145\n",
      "Number of POI: 18, no. of non-POI: 127\n",
      "Number of features used:  21\n"
     ]
    }
   ],
   "source": [
    "# 异常值， 去掉total\n",
    "def remove_outerliers(data_dict,names):\n",
    "    for name in names:\n",
    "        data_dict.pop(name, 0)\n",
    "    return data_dict\n",
    "\n",
    "def dateset_summary(data_dic):\n",
    "    n_poi,n_non_poi = 0,0\n",
    "    for key in data_dict.keys():\n",
    "        if data_dict[key]['poi']==1:\n",
    "            n_poi+=1\n",
    "        else:\n",
    "            n_non_poi+=1        \n",
    "    print \"Total number of data points: \", len(data_dict)\n",
    "    print \"Number of POI: %d, no. of non-POI: %d\"% (n_poi, n_non_poi)\n",
    "    print \"Number of features used: \",len(data_dict['METTS MARK']) # randomly pick one name, get the number of features.\n",
    "\n",
    "outliers_names = ['TOTAL']#,'LAVORATO JOHN J'\n",
    "\n",
    "data_dict = remove_outerliers(data_dict,outliers_names)\n",
    "dateset_summary(dateset_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        to_messages  from_poi_to_this_person  from_messages  \\\n",
      "count     86.000000                86.000000      86.000000   \n",
      "mean    2073.860465                64.895349     608.790698   \n",
      "std     2582.700981                86.979244    1841.033949   \n",
      "min       57.000000                 0.000000      12.000000   \n",
      "25%      541.250000                10.000000      22.750000   \n",
      "50%     1211.000000                35.000000      41.000000   \n",
      "75%     2634.750000                72.250000     145.500000   \n",
      "max    15149.000000               528.000000   14368.000000   \n",
      "\n",
      "       from_this_person_to_poi  shared_receipt_with_poi  \n",
      "count                86.000000                86.000000  \n",
      "mean                 41.232558              1176.465116  \n",
      "std                 100.073111              1178.317641  \n",
      "min                   0.000000                 2.000000  \n",
      "25%                   1.000000               249.750000  \n",
      "50%                   8.000000               740.500000  \n",
      "75%                  24.750000              1888.250000  \n",
      "max                 609.000000              5521.000000  \n"
     ]
    }
   ],
   "source": [
    "print data_df[email_fatures].apply(NaNs_to_None, axis=0).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "salary                        0\n",
      "to_messages                  59\n",
      "deferral_payments             0\n",
      "total_payments                0\n",
      "exercised_stock_options       0\n",
      "bonus                         0\n",
      "restricted_stock              0\n",
      "shared_receipt_with_poi      59\n",
      "restricted_stock_deferred     0\n",
      "total_stock_value             0\n",
      "expenses                      0\n",
      "loan_advances                 0\n",
      "from_messages                59\n",
      "other                         0\n",
      "from_this_person_to_poi      59\n",
      "poi                           0\n",
      "director_fees                 0\n",
      "deferred_income               0\n",
      "long_term_incentive           0\n",
      "email_address                34\n",
      "from_poi_to_this_person      59\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_df = pd.DataFrame.from_dict(data_dict,orient='index')\n",
    "\n",
    "financial_features = ['salary', 'deferral_payments', 'total_payments', 'loan_advances', 'bonus'\n",
    "                 , 'restricted_stock_deferred', 'deferred_income', 'total_stock_value', 'expenses'\n",
    "                 , 'exercised_stock_options', 'other', 'long_term_incentive', 'restricted_stock'\n",
    "                 , 'director_fees']\n",
    "email_fatures = ['to_messages','from_poi_to_this_person', 'from_messages', 'from_this_person_to_poi'\n",
    "                 , 'shared_receipt_with_poi']  # remove 'email_address'\n",
    "def NaNs_to_0s(col):\n",
    "    return [0 if ele=='NaN' else ele for ele in col]\n",
    "\n",
    "def NaNs_to_None(col):\n",
    "    return [None if ele=='NaN' else ele for ele in col]\n",
    "\n",
    "def count_NAN(col):\n",
    "    return sum(1 for ele in col if ele == 'NaN')\n",
    "\n",
    "data_df[financial_features] = data_df[financial_features].apply(NaNs_to_0s, axis=0)\n",
    "data_df['poi'] = data_df['poi'].astype(int)\n",
    "print data_df.apply(count_NAN, axis=0)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11bc7fdd0>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEaCAYAAAAsQ0GGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDw39+bI31sIyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11bcb1c10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "data_df.boxplot('bonus', by='poi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "make new feature \n",
    "1. 'email_features_miss': if email_features is missing. next step, missing email_features will be\n",
    "transformed to 0, which should by different from missing financial features.   \n",
    "2. poi_rate_to_messages = from_this_person_to_poi/to_messages  \n",
    "3. poi_rate_from_messages = from_poi_to_this_person/from_messages\n",
    "\n",
    "\"\"\"\n",
    "data_df['email_features_miss'] = data_df.apply(lambda x: 1 if x[\"to_messages\"]=='NaN' else 0, axis = 1)\n",
    "\n",
    "data_df['poi_rate_to_messages'] = data_df.apply(lambda x: 0 if x['from_this_person_to_poi']=='NaN' \\\n",
    "                                                else x['from_this_person_to_poi']*1.0/x['to_messages'], axis=1)\n",
    "\n",
    "data_df['poi_rate_from_messages'] = data_df.apply(lambda x: 0 if x['from_poi_to_this_person']=='NaN'\\\n",
    "                                                  else x['from_poi_to_this_person']*1.0/x['from_messages'], axis =1)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"create new features\n",
    "\"\"\"\n",
    "def get_new(col,p):\n",
    "    return (data_df[col].apply(abs)/(10**(p-1))%10).astype(int)\n",
    "def over_zero(ele):\n",
    "    if ele>0:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def add_new_features(df):\n",
    "    df[\"bonus_over_zero\"] = df['bonus'].apply(over_zero)\n",
    "    df[\"bonus_six\"] = get_new(\"bonus\",6)\n",
    "    df[\"bonus_seven\"] = get_new(\"bonus\",7)\n",
    "    \n",
    "    df[\"expenses_over_zero\"] = df[\"expenses\"].apply(over_zero)\n",
    "    df[\"expenses_five\"] = get_new(\"expenses\",5)\n",
    "    df[\"expenses_six\"] = get_new(\"expenses\",6)\n",
    "    \n",
    "    df[\"exercised_stock_options_over_zero\"] = df[\"exercised_stock_options\"].apply(over_zero)\n",
    "    df[\"exercised_stock_options_six\"] = get_new(\"exercised_stock_options\",6)\n",
    "    df[\"exercised_stock_options_seven\"] = get_new(\"exercised_stock_options\",7)\n",
    "    df[\"exercised_stock_options_eight\"] = get_new(\"exercised_stock_options\",8)\n",
    "    \n",
    "    df[\"salary_over_zero\"] = df[\"salary\"].apply(over_zero)\n",
    "    df[\"salary_six\"] = get_new(\"salary\",6)\n",
    "    df[\"salary_seven\"] = get_new(\"salary\",7)\n",
    "    \n",
    "    df[\"restricted_stock_over_zero\"] = df[\"restricted_stock\"].apply(over_zero)\n",
    "    df[\"restricted_stock_six\"] = get_new(\"restricted_stock\",6)\n",
    "    df[\"restricted_stock_seven\"] = get_new(\"restricted_stock\",7)\n",
    "    df[\"restricted_stock_eight\"] = get_new(\"restricted_stock\",8)\n",
    "    \n",
    "    df[\"deferred_income_over_zero\"] = df[\"deferred_income\"].apply(over_zero)\n",
    "    df[\"deferred_income_five\"] = get_new(\"deferred_income\",5)\n",
    "    df[\"deferred_income_six\"] = get_new(\"deferred_income\",6)\n",
    "    df[\"deferred_income_seven\"] = get_new(\"deferred_income\",7)\n",
    "    \n",
    "    df[\"other_over_zero\"] = df[\"other\"].apply(over_zero)\n",
    "    df[\"other_six\"] = get_new(\"other\",6)\n",
    "    df[\"other_seven\"] = get_new(\"other\",7)\n",
    "    df[\"other_eight\"] = get_new(\"other\",8)\n",
    "    return df\n",
    "\n",
    "data_df = add_new_features(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get mydata(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_full_list = list(data_df.columns.values)\n",
    "features_full_list.remove('email_address')\n",
    "features_full_list.remove('poi')\n",
    "features_full_list = ['poi'] +features_full_list\n",
    "data_full_dic = data_df.to_dict(orient='index')\n",
    "\n",
    "\n",
    "def get_train_test_dataset(my_dataset,features_list):\n",
    "    #Extract features and labels from dataset for local testing\n",
    "    data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "    labels, features = targetFeatureSplit(data)\n",
    "    # TODO: Shuffle the data\n",
    "    from sklearn.utils import shuffle\n",
    "    features, labels = shuffle(features, labels, random_state=1)\n",
    "    \n",
    "    # split train test dataset\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n",
    "X_train, X_test, y_train, y_test = get_train_test_dataset(data_full_dic,features_full_list)  \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,\n",
       "        0.,  0.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "min_max_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train_scaled = min_max_scaler.fit_transform(X_train)\n",
    "X_test_scaled = min_max_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## select features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "select important features \n",
    "\"\"\"\n",
    "def select_features(X_train,y_train,X_test, method='tree',k=None):\n",
    "    from sklearn.utils import shuffle\n",
    "    X_train, y_train = shuffle(X_train, y_train, random_state=0)\n",
    "    if method == 'tree':\n",
    "        \n",
    "        from sklearn.ensemble import ExtraTreesClassifier\n",
    "        from sklearn.feature_selection import SelectFromModel   \n",
    "\n",
    "        selection_tree = ExtraTreesClassifier(random_state=32)\n",
    "        selection_tree = selection_tree.fit(X_train, y_train)\n",
    "\n",
    "        model_tree = SelectFromModel(selection_tree, prefit=True)\n",
    "        X_train_new = model_tree.transform(X_train)\n",
    "        X_test_new = model_tree.transform(X_test)\n",
    "        \n",
    "        print \"shape of X_train: \", X_train.shape\n",
    "        print \"shape of X_train_new: \", X_train_new.shape    \n",
    "        return selection_tree,X_train_new,X_test_new\n",
    "    \n",
    "    elif method == 'kbest' and k:\n",
    "        from sklearn.feature_selection import SelectKBest\n",
    "        from sklearn.feature_selection import f_classif\n",
    "\n",
    "        selection_k= SelectKBest(f_classif, k=k).fit(X_train, y_train)\n",
    "        X_train_new = selection_k.transform(X_train)\n",
    "        X_test_new = selection_k.transform(X_test)\n",
    "        print \"shape of X_train: \", X_train.shape\n",
    "        print \"shape of X_train_new: \", X_train_new.shape   \n",
    "        return selection_k,X_train_new,X_test_new\n",
    "        \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#selection_tree,X_train_new,X_test_new = select_features(X_train_scaled,y_train,X_test_scaled)\n",
    "X_train_new,X_test_new = X_train_scaled,X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X_train:  (101, 22)\n",
      "shape of X_train_new:  (101, 10)\n"
     ]
    }
   ],
   "source": [
    "selection_k,X_train_new,X_test_new = select_features(X_train_scaled,y_train,X_test_scaled,method='kbest',k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def train_model(classifier,features_train,labels_train,features_test):\n",
    "    clf = classifier\n",
    "    clf.fit(features_train, labels_train)\n",
    "    labels_pred = clf.predict(features_test)\n",
    "    return clf,labels_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluation_metric(labels_test,labels_pred):\n",
    "    from sklearn.metrics import recall_score\n",
    "    from sklearn.metrics import precision_score\n",
    "    from sklearn.metrics import f1_score\n",
    "    \n",
    "    print \"recall_score: \",recall_score(y_test, labels_pred)\n",
    "    print \"precision_score: \",precision_score(labels_test, labels_pred)  \n",
    "    print \"f1_score: \",f1_score(labels_test, labels_pred)  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用tree 的到的features，建模，问题\n",
    "navie bayers 和 decision tree 完全反的;    \n",
    "SVM，randomforest 出现no TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_score:  0.666666666667\n",
      "precision_score:  0.285714285714\n",
      "f1_score:  0.4\n"
     ]
    }
   ],
   "source": [
    "# naive bayers\n",
    "clf_nb,y_pred_nb = train_model(GaussianNB(),X_train_new,y_train,X_test_new)\n",
    "evaluation_metric(y_test,y_pred_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_score:  0.0\n",
      "precision_score:  0.0\n",
      "f1_score:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weidian1/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/weidian1/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#svm\n",
    "clf_svm,y_pred_svm = train_model(SVC(),X_train_new,y_train,X_test_new)\n",
    "evaluation_metric(y_test,y_pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_score:  0.0\n",
      "precision_score:  0.0\n",
      "f1_score:  0.0\n"
     ]
    }
   ],
   "source": [
    "# decision tree\n",
    "clf_dtree,y_pred_stree = train_model(tree.DecisionTreeClassifier(),X_train_new,y_train,X_test_new)\n",
    "evaluation_metric(y_test,y_pred_stree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_score:  0.0\n",
      "precision_score:  0.0\n",
      "f1_score:  0.0\n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "\n",
    "clf_froest,y_pred_forest = train_model(RandomForestClassifier(n_estimators=10),X_train_new,y_train,X_test_new)\n",
    "evaluation_metric(y_test,y_pred_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kbest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_score:  0.666666666667\n",
      "precision_score:  0.285714285714\n",
      "f1_score:  0.4\n"
     ]
    }
   ],
   "source": [
    "# naive bayers\n",
    "clf_nb,y_pred_nb = train_model(GaussianNB(),X_train_new,y_train,X_test_new)\n",
    "evaluation_metric(y_test,y_pred_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_score:  0.0\n",
      "precision_score:  0.0\n",
      "f1_score:  0.0\n"
     ]
    }
   ],
   "source": [
    "#svm\n",
    "clf_svm,y_pred_svm = train_model(SVC(),X_train_new,y_train,X_test_new)\n",
    "evaluation_metric(y_test,y_pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_score:  0.0\n",
      "precision_score:  0.0\n",
      "f1_score:  0.0\n"
     ]
    }
   ],
   "source": [
    "# decision tree\n",
    "clf_dtree,y_pred_stree = train_model(tree.DecisionTreeClassifier(),X_train_new,y_train,X_test_new)\n",
    "evaluation_metric(y_test,y_pred_stree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_score:  0.0\n",
      "precision_score:  0.0\n",
      "f1_score:  0.0\n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "\n",
    "clf_froest,y_pred_forest = train_model(RandomForestClassifier(n_estimators=10),X_train_new,y_train,X_test_new)\n",
    "evaluation_metric(y_test,y_pred_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipiline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "estimators = [('reduce_dim', PCA()), ('clf', SVC())]\n",
    "pipe = Pipeline(estimators)\n",
    "pipe \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe.steps[0]\n",
    "pipe.named_steps['reduce_dim']\n",
    "pipe.set_params(clf__C=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "params = dict(reduce_dim__n_components=[2, 5, 10],\n",
    "              clf__C=[0.1, 10, 100])\n",
    "grid_search = GridSearchCV(pipe, param_grid=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "params = dict(reduce_dim=[None, PCA(5), PCA(10)],\n",
    "              clf=[SVC(), LogisticRegression()],\n",
    "              clf__C=[0.1, 10, 100])\n",
    "grid_search = GridSearchCV(pipe, param_grid=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = Pipeline([\n",
    "  ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\"))),\n",
    "  ('classification', RandomForestClassifier())\n",
    "])\n",
    "clf.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel  \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "min_max_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "model_tree = SelectFromModel(ExtraTreesClassifier(random_state=32), prefit=True)\n",
    "clf = GaussianNB()\n",
    "        \n",
    "estimators = [('scaler',min_max_scaler)\n",
    "              ,('selector',model_tree)\n",
    "              ,('clf',clf)]\n",
    "pipe= Pipeline(estimators)\n",
    "\n",
    "params = dict(reduce_dim__n_components=[2, 5, 10],\n",
    "              clf__C=[0.1, 10, 100])\n",
    "grid_search = GridSearchCV(pipe, param_grid=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__C': [0.1, 10, 100], 'reduce_dim__n_components': [2, 5, 10]}"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(reduce_dim__n_components=[2, 5, 10],\n",
    "              clf__C=[0.1, 10, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy import mean,std\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "class EstimatorSelectionHelper:\n",
    "    def __init__(self, models, params):\n",
    "        if not set(models.keys()).issubset(set(params.keys())):\n",
    "            missing_params = list(set(models.keys()) - set(params.keys()))\n",
    "            raise ValueError(\"Some estimators are missing parameters: %s\" % missing_params)\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "\n",
    "    def fit(self, X, y, cv=3, n_jobs=1, verbose=1, scoring=None, refit=False):\n",
    "        for key in self.keys:\n",
    "            print(\"Running GridSearchCV for %s.\" % key)\n",
    "            model = self.models[key]\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs, \n",
    "                              verbose=verbose, scoring=scoring, refit=refit)\n",
    "            gs.fit(X,y)\n",
    "            self.grid_searches[key] = gs    \n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                 'estimator': key,\n",
    "                 'min_score': min(scores),\n",
    "                 'max_score': max(scores),\n",
    "                 'mean_score': mean(scores),\n",
    "                 'std_score': std(scores),\n",
    "            }\n",
    "            return pd.Series(dict(params.items() + d.items()))\n",
    "\n",
    "        rows = [row(k, gsc.cv_validation_scores, gsc.parameters) \n",
    "                     for k in self.keys\n",
    "                     for gsc in self.grid_searches[k].grid_scores_]\n",
    "        df = pd.concat(rows, axis=1).T.sort_values(by=[sort_by], ascending=False)\n",
    "\n",
    "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "\n",
    "        return df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import (ExtraTreesClassifier, RandomForestClassifier, \n",
    "                              AdaBoostClassifier, GradientBoostingClassifier)\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "models1 = { \n",
    "    'ExtraTreesClassifier': ExtraTreesClassifier(),\n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'AdaBoostClassifier': AdaBoostClassifier(),\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "    'SVC': SVC()\n",
    "}\n",
    "\n",
    "params1 = { \n",
    "    'ExtraTreesClassifier': { 'n_estimators': [16, 32] },\n",
    "    'RandomForestClassifier': { 'n_estimators': [16, 32] },\n",
    "    'AdaBoostClassifier':  { 'n_estimators': [16, 32] },\n",
    "    'GradientBoostingClassifier': { 'n_estimators': [16, 32], 'learning_rate': [0.8, 1.0] },\n",
    "    'SVC': [\n",
    "        {'kernel': ['linear'], 'C': [1, 10]},\n",
    "        {'kernel': ['rbf'], 'C': [1, 10], 'gamma': [0.001, 0.0001]},\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for SVC.\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "Running GridSearchCV for AdaBoostClassifier.\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for GradientBoostingClassifier.\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  12 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for ExtraTreesClassifier.\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Running GridSearchCV for RandomForestClassifier.\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "helper1 = EstimatorSelectionHelper(models1, params1)\n",
    "helper1.fit(X_train_new,y_train,cv=3, scoring='f1', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>C</th>\n",
       "      <th>gamma</th>\n",
       "      <th>kernel</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.249444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.546032</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.110337</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.546032</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.110337</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.0808122</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.434921</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.100289</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.329983</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>linear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.329983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.329983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>linear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     estimator min_score mean_score max_score  std_score    C  \\\n",
       "7           AdaBoostClassifier       0.4   0.733333         1   0.249444  NaN   \n",
       "8   GradientBoostingClassifier       0.4   0.546032  0.666667   0.110337  NaN   \n",
       "11  GradientBoostingClassifier       0.4   0.546032  0.666667   0.110337  NaN   \n",
       "9   GradientBoostingClassifier       0.4   0.457143  0.571429  0.0808122  NaN   \n",
       "10  GradientBoostingClassifier  0.333333   0.434921  0.571429   0.100289  NaN   \n",
       "1                          SVC         0   0.433333       0.8   0.329983   10   \n",
       "6           AdaBoostClassifier         0   0.433333       0.8   0.329983  NaN   \n",
       "13        ExtraTreesClassifier         0   0.433333       0.8   0.329983  NaN   \n",
       "0                          SVC         0   0.166667       0.5   0.235702    1   \n",
       "12        ExtraTreesClassifier         0   0.166667       0.5   0.235702  NaN   \n",
       "14      RandomForestClassifier         0   0.166667       0.5   0.235702  NaN   \n",
       "15      RandomForestClassifier         0   0.166667       0.5   0.235702  NaN   \n",
       "2                          SVC         0          0         0          0    1   \n",
       "3                          SVC         0          0         0          0    1   \n",
       "4                          SVC         0          0         0          0   10   \n",
       "5                          SVC         0          0         0          0   10   \n",
       "\n",
       "     gamma  kernel learning_rate n_estimators  \n",
       "7      NaN     NaN           NaN           32  \n",
       "8      NaN     NaN           0.8           16  \n",
       "11     NaN     NaN             1           32  \n",
       "9      NaN     NaN           0.8           32  \n",
       "10     NaN     NaN             1           16  \n",
       "1      NaN  linear           NaN          NaN  \n",
       "6      NaN     NaN           NaN           16  \n",
       "13     NaN     NaN           NaN           32  \n",
       "0      NaN  linear           NaN          NaN  \n",
       "12     NaN     NaN           NaN           16  \n",
       "14     NaN     NaN           NaN           16  \n",
       "15     NaN     NaN           NaN           32  \n",
       "2    0.001     rbf           NaN          NaN  \n",
       "3   0.0001     rbf           NaN          NaN  \n",
       "4    0.001     rbf           NaN          NaN  \n",
       "5   0.0001     rbf           NaN          NaN  "
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper1.score_summary(sort_by='mean_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                 'estimator': key,\n",
    "                 'min_score': min(scores),\n",
    "                 'max_score': max(scores),\n",
    "                 'mean_score': mean(scores),\n",
    "                 'std_score': std(scores),\n",
    "            }\n",
    "            return pd.Series(dict(params.items() + d.items()))\n",
    "\n",
    "        rows = [row(k, gsc.cv_validation_scores, gsc.parameters) \n",
    "                     for k in self.keys\n",
    "                     for gsc in self.grid_searches[k].grid_scores_]\n",
    "        df = pd.concat(rows, axis=1).T.sort([sort_by], ascending=False)\n",
    "\n",
    "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "        return df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'n_estimators': [16, 32]}, pre_dispatch='2*n_jobs',\n",
       "       refit=False, scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper1.grid_searches['AdaBoostClassifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('n_estimators', 16),\n",
       " ('std_score', 0.2),\n",
       " ('min_score', 0.3),\n",
       " ('estimator', 'AdaBoostClassifier'),\n",
       " ('max_score', 0.8),\n",
       " ('mean_score', 0.44)]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper1.grid_searches['AdaBoostClassifier'].grid_scores_[0].parameters.items()+d.items()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.42970, std: 0.32998, params: {'n_estimators': 16},\n",
       " mean: 0.73267, std: 0.24944, params: {'n_estimators': 32}]"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper1.grid_searches['AdaBoostClassifier'].grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('n_estimators', 16)]"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper1.grid_searches['AdaBoostClassifier'].grid_scores_[0].parameters.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('std_score', 0.2),\n",
       " ('min_score', 0.3),\n",
       " ('estimator', 'AdaBoostClassifier'),\n",
       " ('max_score', 0.8),\n",
       " ('mean_score', 0.44)]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "            d = {\n",
    "                 'estimator': 'AdaBoostClassifier',\n",
    "                 'min_score': 0.3,\n",
    "                 'max_score': 0.8,\n",
    "                 'mean_score': 0.44,\n",
    "                 'std_score': 0.2,\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('std_score', 0.2),\n",
       " ('min_score', 0.3),\n",
       " ('estimator', 'AdaBoostClassifier'),\n",
       " ('max_score', 0.8),\n",
       " ('mean_score', 0.44)]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.items()+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.42970, std: 0.32998, params: {'n_estimators': 16},\n",
       " mean: 0.73267, std: 0.24944, params: {'n_estimators': 32}]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper1.grid_searches['AdaBoostClassifier'].grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'kernel': ('linear', 'rbf'), 'C': [1, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "iris = datasets.load_iris()\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "svr = svm.SVC()\n",
    "clf = GridSearchCV(svr, parameters)\n",
    "clf.fit(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 0.00063491,  0.00046666,  0.00044266,  0.00074569]),\n",
       " 'mean_score_time': array([ 0.00031439,  0.00036033,  0.00029103,  0.00052603]),\n",
       " 'mean_test_score': array([ 0.98      ,  0.97333333,  0.97333333,  0.98      ]),\n",
       " 'mean_train_score': array([ 0.98999802,  0.98336304,  0.97999604,  0.97999604]),\n",
       " 'param_C': masked_array(data = [1 1 10 10],\n",
       "              mask = [False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_kernel': masked_array(data = ['linear' 'rbf' 'linear' 'rbf'],\n",
       "              mask = [False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': ({'C': 1, 'kernel': 'linear'},\n",
       "  {'C': 1, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'kernel': 'linear'},\n",
       "  {'C': 10, 'kernel': 'rbf'}),\n",
       " 'rank_test_score': array([1, 3, 3, 1], dtype=int32),\n",
       " 'split0_test_score': array([ 1.        ,  0.98039216,  1.        ,  0.98039216]),\n",
       " 'split0_train_score': array([ 0.97979798,  0.96969697,  0.95959596,  0.95959596]),\n",
       " 'split1_test_score': array([ 0.96078431,  0.96078431,  0.92156863,  0.96078431]),\n",
       " 'split1_train_score': array([ 1.,  1.,  1.,  1.]),\n",
       " 'split2_test_score': array([ 0.97916667,  0.97916667,  1.        ,  1.        ]),\n",
       " 'split2_train_score': array([ 0.99019608,  0.98039216,  0.98039216,  0.98039216]),\n",
       " 'std_fit_time': array([  2.31217596e-04,   2.91042156e-05,   3.72097666e-05,\n",
       "          1.20617077e-04]),\n",
       " 'std_score_time': array([  8.05333431e-05,   7.48511154e-05,   5.67924644e-05,\n",
       "          1.76408304e-04]),\n",
       " 'std_test_score': array([ 0.01617914,  0.00902067,  0.03715363,  0.01592466]),\n",
       " 'std_train_score': array([ 0.00824863,  0.01254825,  0.01649726,  0.01649726])}"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function _passthrough_scorer at 0x10aa44410>\n"
     ]
    }
   ],
   "source": [
    "print clf.scorer_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = {\n",
    "'split0_test_score'  : [0.8, 0.7, 0.8, 0.9],\n",
    "'split1_test_score'  : [0.82, 0.5, 0.7, 0.78],\n",
    "'mean_test_score'    : [0.81, 0.60, 0.75, 0.82],\n",
    "'std_test_score'     : [0.02, 0.01, 0.03, 0.03],\n",
    "'rank_test_score'    : [2, 4, 3, 1],\n",
    "\n",
    "'mean_fit_time'      : [0.73, 0.63, 0.43, 0.49],\n",
    "'std_fit_time'       : [0.01, 0.02, 0.01, 0.01],\n",
    "'mean_score_time'    : [0.007, 0.06, 0.04, 0.04],\n",
    "'std_score_time'     : [0.001, 0.002, 0.003, 0.005]}\n",
    "#'params'             : [{'kernel': 'poly', 'degree': 2}],\n",
    "#}\n",
    "\n",
    "d_df = pd.DataFrame.from_dict(d,orient = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.81</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.60</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  rank_test_score  \\\n",
       "0           0.73            0.007             0.81                2   \n",
       "1           0.63            0.060             0.60                4   \n",
       "2           0.43            0.040             0.75                3   \n",
       "3           0.49            0.040             0.82                1   \n",
       "\n",
       "   split0_test_score  split1_test_score  std_fit_time  std_score_time  \\\n",
       "0                0.8               0.82          0.01           0.001   \n",
       "1                0.7               0.50          0.02           0.002   \n",
       "2                0.8               0.70          0.01           0.003   \n",
       "3                0.9               0.78          0.01           0.005   \n",
       "\n",
       "   std_test_score  \n",
       "0            0.02  \n",
       "1            0.01  \n",
       "2            0.03  \n",
       "3            0.03  "
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rank_test_score', [2, 4, 3, 1]),\n",
       " ('std_score_time', [0.001, 0.002, 0.003, 0.005]),\n",
       " ('mean_test_score', [0.81, 0.6, 0.75, 0.82]),\n",
       " ('std_test_score', [0.02, 0.01, 0.03, 0.03]),\n",
       " ('mean_score_time', [0.007, 0.06, 0.04, 0.04]),\n",
       " ('mean_fit_time', [0.73, 0.63, 0.43, 0.49]),\n",
       " ('split0_test_score', [0.8, 0.7, 0.8, 0.9]),\n",
       " ('split1_test_score', [0.82, 0.5, 0.7, 0.78]),\n",
       " ('std_fit_time', [0.01, 0.02, 0.01, 0.01])]"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['k', 'k', 'k']"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['k']*3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testd_d={}\n",
    "testd_d['ce'] ='cew'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy import mean,std\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "#reload(GridSearchCV)\n",
    "#from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "'''\n",
    "refit : boolean, default=True\n",
    "Refit the best estimator with the entire dataset. \n",
    "If “False”, it is impossible to make predictions using this GridSearchCV instance after fitting.\n",
    "'''\n",
    "\n",
    "\n",
    "class ModelsSelector(object):\n",
    "\t\"\"\"docstring for ClassName\"\"\"\n",
    "\tdef __init__(self, models, params):\n",
    "\t\tif not set(models.keys()).issubset(set(params.keys())):\n",
    "\t\t\tmiss_models =  set(models.keys()) - set(params.keys())\n",
    "\t\t\traise ValueError(\"Some models are missing parameters %s: .\" % miss_models)\n",
    "\t\tself.models = models\n",
    "\t\tself.params = params\n",
    "\t\tself.keys = models.keys()\n",
    "\t\tself.grid_select = {}\n",
    "\n",
    "\tdef fit(self, X, y, cv=3, scoring=None, refit=False, verbose=1, n_jobs=1):\n",
    "\t\tfor key in self.keys:\n",
    "\t\t\tprint (\"Running GridSelectCV for %s .\" % key)\n",
    "\t\t\tmodel = self.models[key]\n",
    "\t\t\tparams = self.params[key]\n",
    "\t\t\tgs_cv = GridSearchCV(model, param_grid=params, cv=cv, scoring=scoring,\n",
    "\t\t\t\t\t\t\t\tn_jobs=n_jobs, refit=refit, verbose=verbose)\n",
    "\t\t\tgs_cv.fit\n",
    "\t\t\tself.grid_select[key] = gs_cv\n",
    "\n",
    "\n",
    "\tdef score_summary(self,sort_by='mean_score'):\n",
    "\t\tevaluate_keys = ['mean_test_score','std_test_score','mean_train_score','std_train_score','params','rank_test_score']\n",
    "\t\tcv_result_dfs = []\n",
    "\t\tfor k in self.keys:\n",
    "\t\t\tcv_result_dict = {}\n",
    "\t\t\tfor gs_cv_result_k, gs_cv_result_v in self.grid_select[k].cv_results_:\n",
    "\t\t\t\tif gs_cv_result_k in evaluate_keys:\n",
    "\t\t\t\t\tcv_result_dict['gs_cv_result_k'] = gs_cv_result_v\n",
    " \t\t\tcv_result_dict['estimator'] = [k]*len(cv_results_['mean_test_score'])\n",
    " \t\t\tcv_result_df = pd.DataFrame.from_dict(cv_result_dict,orient='columns')\n",
    " \t\t\tcv_result_dfs.append(cv_result_df)\n",
    " #[mydict[x] for x in evaluate_keys]\n",
    " \t\tcv_results = pd.concat(cv_result_dfs)\n",
    " \t\treturn cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSelectCV for SVC .\n",
      "Running GridSelectCV for AdaBoostClassifier .\n",
      "Running GridSelectCV for GradientBoostingClassifier .\n",
      "Running GridSelectCV for ExtraTreesClassifier .\n",
      "Running GridSelectCV for RandomForestClassifier .\n"
     ]
    }
   ],
   "source": [
    "helper2 = ModelsSelector(models1, params1)\n",
    "helper2.fit(X_train_new,y_train,cv=3, scoring='f1', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'cv_results_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-fc648d9c5a77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhelper2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msort_by\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_score'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-cd35c68817f7>\u001b[0m in \u001b[0;36mscore_summary\u001b[0;34m(self, sort_by)\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                         \u001b[0mcv_result_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                         \u001b[0;32mfor\u001b[0m \u001b[0mgs_cv_result_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgs_cv_result_v\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_select\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m                                 \u001b[0;32mif\u001b[0m \u001b[0mgs_cv_result_k\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevaluate_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                                         \u001b[0mcv_result_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gs_cv_result_k'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgs_cv_result_v\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'cv_results_'"
     ]
    }
   ],
   "source": [
    "helper2.score_summary(sort_by='mean_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.18.1'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
