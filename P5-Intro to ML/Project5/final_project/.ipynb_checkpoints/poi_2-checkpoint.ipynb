{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/weidian1/Documents/GitHub/Udacity-DAND/P5-Intro to ML/Project5/final_project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weidian1/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "#sys.path.append(\"../pylof-master/\")\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "\n",
    "### Task 1: Select what features you'll use.\n",
    "### features_list is a list of strings, each of which is a feature name.\n",
    "### The first feature must be \"poi\".\n",
    "#features_list = ['poi','salary',''] # You will need to use more features\n",
    "\n",
    "### Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of data points:  145\n",
      "Number of POI: 18, no. of non-POI: 127\n",
      "Number of features used:  21\n"
     ]
    }
   ],
   "source": [
    "# 异常值， 去掉total\n",
    "def remove_outerliers(data_dict):\n",
    "    data_dict.pop('TOTAL', 0)\n",
    "    return data_dict\n",
    "\n",
    "def dateset_summary(data_dic):\n",
    "    n_poi,n_non_poi = 0,0\n",
    "    for key in data_dict.keys():\n",
    "        if data_dict[key]['poi']==1:\n",
    "            n_poi+=1\n",
    "        else:\n",
    "            n_non_poi+=1        \n",
    "    print \"Total number of data points: \", len(data_dict)\n",
    "    print \"Number of POI: %d, no. of non-POI: %d\"% (n_poi, n_non_poi)\n",
    "    print \"Number of features used: \",len(data_dict['METTS MARK']) # randomly pick one name, get the number of features.\n",
    "\n",
    "data_dict = remove_outerliers(data_dict)\n",
    "dateset_summary(dateset_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "salary                        0\n",
      "to_messages                  59\n",
      "deferral_payments             0\n",
      "total_payments                0\n",
      "exercised_stock_options       0\n",
      "bonus                         0\n",
      "restricted_stock              0\n",
      "shared_receipt_with_poi      59\n",
      "restricted_stock_deferred     0\n",
      "total_stock_value             0\n",
      "expenses                      0\n",
      "loan_advances                 0\n",
      "from_messages                59\n",
      "other                         0\n",
      "from_this_person_to_poi      59\n",
      "poi                           0\n",
      "director_fees                 0\n",
      "deferred_income               0\n",
      "long_term_incentive           0\n",
      "email_address                34\n",
      "from_poi_to_this_person      59\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_df = pd.DataFrame.from_dict(data_dict,orient='index')\n",
    "\n",
    "financial_features = ['salary', 'deferral_payments', 'total_payments', 'loan_advances', 'bonus'\n",
    "                 , 'restricted_stock_deferred', 'deferred_income', 'total_stock_value', 'expenses'\n",
    "                 , 'exercised_stock_options', 'other', 'long_term_incentive', 'restricted_stock'\n",
    "                 , 'director_fees']\n",
    "email_fatures = ['to_messages','from_poi_to_this_person', 'from_messages', 'from_this_person_to_poi'\n",
    "                 , 'shared_receipt_with_poi']  # remove 'email_address'\n",
    "def NaNs_to_0s(col):\n",
    "    return [0 if ele=='NaN' else ele for ele in col]\n",
    "\n",
    "def count_NAN(col):\n",
    "    return sum(1 for ele in col if ele == 'NaN')\n",
    "\n",
    "data_df[financial_features] = data_df[financial_features].apply(NaNs_to_0s, axis=0)\n",
    "data_df['poi'] = data_df['poi'].astype(int)\n",
    "print data_df.apply(count_NAN, axis=0)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make new feature 'email_features_miss': if email_features is missing. next step, missing email_features will be\n",
    "#transformed to 0, which should by different from missing financial features. \n",
    "data_df['email_features_miss'] = data_df.apply(lambda x: 1 if x[\"to_messages\"]=='NaN' else 0, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"create new features\n",
    "\"\"\"\n",
    "def get_new(col,p):\n",
    "    return (data_df[col].apply(abs)/(10**(p-1))%10).astype(int)\n",
    "def over_zero(ele):\n",
    "    if ele>0:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def add_new_features(df):\n",
    "    df[\"bonus_over_zero\"] = df['bonus'].apply(over_zero)\n",
    "    df[\"bonus_six\"] = get_new(\"bonus\",6)\n",
    "    df[\"bonus_seven\"] = get_new(\"bonus\",7)\n",
    "    \n",
    "    df[\"expenses_over_zero\"] = df[\"expenses\"].apply(over_zero)\n",
    "    df[\"expenses_five\"] = get_new(\"expenses\",5)\n",
    "    df[\"expenses_six\"] = get_new(\"expenses\",6)\n",
    "    \n",
    "    df[\"exercised_stock_options_over_zero\"] = df[\"exercised_stock_options\"].apply(over_zero)\n",
    "    df[\"exercised_stock_options_six\"] = get_new(\"exercised_stock_options\",6)\n",
    "    df[\"exercised_stock_options_seven\"] = get_new(\"exercised_stock_options\",7)\n",
    "    df[\"exercised_stock_options_eight\"] = get_new(\"exercised_stock_options\",8)\n",
    "    \n",
    "    df[\"salary_over_zero\"] = df[\"salary\"].apply(over_zero)\n",
    "    df[\"salary_six\"] = get_new(\"salary\",6)\n",
    "    df[\"salary_seven\"] = get_new(\"salary\",7)\n",
    "    \n",
    "    df[\"restricted_stock_over_zero\"] = df[\"restricted_stock\"].apply(over_zero)\n",
    "    df[\"restricted_stock_six\"] = get_new(\"restricted_stock\",6)\n",
    "    df[\"restricted_stock_seven\"] = get_new(\"restricted_stock\",7)\n",
    "    df[\"restricted_stock_eight\"] = get_new(\"restricted_stock\",8)\n",
    "    \n",
    "    df[\"deferred_income_over_zero\"] = df[\"deferred_income\"].apply(over_zero)\n",
    "    df[\"deferred_income_five\"] = get_new(\"deferred_income\",5)\n",
    "    df[\"deferred_income_six\"] = get_new(\"deferred_income\",6)\n",
    "    df[\"deferred_income_seven\"] = get_new(\"deferred_income\",7)\n",
    "    \n",
    "    df[\"other_over_zero\"] = df[\"other\"].apply(over_zero)\n",
    "    df[\"other_six\"] = get_new(\"other\",6)\n",
    "    df[\"other_seven\"] = get_new(\"other\",7)\n",
    "    df[\"other_eight\"] = get_new(\"other\",8)\n",
    "    return df\n",
    "\n",
    "data_df = add_new_features(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get mydata(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_full_list = list(data_df.columns.values)\n",
    "features_full_list.remove('email_address')\n",
    "features_full_list.remove('poi')\n",
    "features_full_list = ['poi'] +features_full_list\n",
    "data_full_dic = data_df.to_dict(orient='index')\n",
    "\n",
    "\n",
    "def get_train_test_dataset(my_dataset,features_list):\n",
    "    #Extract features and labels from dataset for local testing\n",
    "    data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "    labels, features = targetFeatureSplit(data)\n",
    "    # TODO: Shuffle the data\n",
    "    from sklearn.utils import shuffle\n",
    "    features, labels = shuffle(features, labels, random_state=1)\n",
    "    \n",
    "    # split train test dataset\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n",
    "X_train, X_test, y_train, y_test = get_train_test_dataset(data_full_dic,features_full_list)  \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "min_max_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train_scaled = min_max_scaler.fit_transform(X_train)\n",
    "X_test_scaled = min_max_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.30531884,  0.47917354,  0.01569801, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.32133942,  0.04429335,  0.01569801, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.27366282,  0.2126213 ,  0.01569801, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ..., \n",
       "       [ 0.15382656,  0.        ,  0.01569801, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.17735845,  0.08172157,  0.18876451, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.16399882,  0.        ,  0.01569801, ...,  0.        ,\n",
       "         0.        ,  1.        ]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## select features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "select important features \n",
    "\"\"\"\n",
    "def select_features(X_train,y_train,X_test, method='tree',k=None):\n",
    "    from sklearn.utils import shuffle\n",
    "    X_train, y_train = shuffle(X_train, y_train, random_state=0)\n",
    "    if method == 'tree':\n",
    "        \n",
    "        from sklearn.ensemble import ExtraTreesClassifier\n",
    "        from sklearn.feature_selection import SelectFromModel   \n",
    "\n",
    "        selection_tree = ExtraTreesClassifier(random_state=32)\n",
    "        selection_tree = selection_tree.fit(X_train, y_train)\n",
    "\n",
    "        model_tree = SelectFromModel(selection_tree, prefit=True)\n",
    "        X_train_new = model_tree.transform(X_train)\n",
    "        X_test_new = model_tree.transform(X_test)\n",
    "        \n",
    "        print \"shape of X_train: \", X_train.shape\n",
    "        print \"shape of X_train_new: \", X_train_new.shape    \n",
    "        return selection_tree,X_train_new,X_test_new\n",
    "    \n",
    "    elif method == 'kbest' and k:\n",
    "        from sklearn.feature_selection import SelectKBest\n",
    "        from sklearn.feature_selection import f_classif\n",
    "\n",
    "        selection_k= SelectKBest(f_classif, k=k).fit(X_train, y_train)\n",
    "        X_train_new = selection_k.transform(X_train)\n",
    "        X_test_new = selection_k.transform(X_test)\n",
    "        print \"shape of X_train: \", X_train.shape\n",
    "        print \"shape of X_train_new: \", X_train_new.shape   \n",
    "        return selection_k,X_train_new,X_test_new\n",
    "        \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X_train:  (101, 45)\n",
      "shape of X_train_new:  (101, 15)\n"
     ]
    }
   ],
   "source": [
    "selection_tree,X_train_new,X_test_new = select_features(X_train_scaled,y_train,X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X_train:  (101, 45)\n",
      "shape of X_train_new:  (101, 10)\n"
     ]
    }
   ],
   "source": [
    "selection_k,X_train_new,X_test_new = select_features(X_train_scaled,y_train,X_test_scaled,method='kbest',k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def train_model(classifier,features_train,labels_train,features_test):\n",
    "    clf = classifier\n",
    "    clf.fit(features_train, labels_train)\n",
    "    labels_pred = clf.predict(features_test)\n",
    "    return clf,labels_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluation_metric(labels_test,labels_pred):\n",
    "    from sklearn.metrics import recall_score\n",
    "    from sklearn.metrics import precision_score\n",
    "    from sklearn.metrics import f1_score\n",
    "    \n",
    "    print \"recall_score: \",recall_score(y_test, labels_pred)\n",
    "    print \"precision_score: \",precision_score(labels_test, labels_pred)  \n",
    "    print \"f1_score: \",f1_score(labels_test, labels_pred)  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用tree 的到的features，建模，问题\n",
    "navie bayers 和 decision tree 完全反的;    \n",
    "SVM，randomforest 出现no TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_score:  0.666666666667\n",
      "precision_score:  0.222222222222\n",
      "f1_score:  0.333333333333\n"
     ]
    }
   ],
   "source": [
    "# naive bayers\n",
    "clf_nb,y_pred_nb = train_model(GaussianNB(),X_train_new,y_train,X_test_new)\n",
    "evaluation_metric(y_test,y_pred_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_score:  0.0\n",
      "precision_score:  0.0\n",
      "f1_score:  0.0\n"
     ]
    }
   ],
   "source": [
    "#svm\n",
    "clf_svm,y_pred_svm = train_model(SVC(),X_train_new,y_train,X_test_new)\n",
    "evaluation_metric(y_test,y_pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_score:  0.222222222222\n",
      "precision_score:  0.4\n",
      "f1_score:  0.285714285714\n"
     ]
    }
   ],
   "source": [
    "# decision tree\n",
    "clf_dtree,y_pred_stree = train_model(tree.DecisionTreeClassifier(),X_train_new,y_train,X_test_new)\n",
    "evaluation_metric(y_test,y_pred_stree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_score:  0.0\n",
      "precision_score:  0.0\n",
      "f1_score:  0.0\n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "\n",
    "clf_froest,y_pred_forest = train_model(RandomForestClassifier(n_estimators=10),X_train_new,y_train,X_test_new)\n",
    "evaluation_metric(y_test,y_pred_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kbest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_score:  0.666666666667\n",
      "precision_score:  0.176470588235\n",
      "f1_score:  0.279069767442\n"
     ]
    }
   ],
   "source": [
    "# naive bayers\n",
    "clf_nb,y_pred_nb = train_model(GaussianNB(),X_train_new,y_train,X_test_new)\n",
    "evaluation_metric(y_test,y_pred_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_score:  0.0\n",
      "precision_score:  0.0\n",
      "f1_score:  0.0\n"
     ]
    }
   ],
   "source": [
    "#svm\n",
    "clf_svm,y_pred_svm = train_model(SVC(),X_train_new,y_train,X_test_new)\n",
    "evaluation_metric(y_test,y_pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_score:  0.111111111111\n",
      "precision_score:  0.166666666667\n",
      "f1_score:  0.133333333333\n"
     ]
    }
   ],
   "source": [
    "# decision tree\n",
    "clf_dtree,y_pred_stree = train_model(tree.DecisionTreeClassifier(),X_train_new,y_train,X_test_new)\n",
    "evaluation_metric(y_test,y_pred_stree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_score:  0.0\n",
      "precision_score:  0.0\n",
      "f1_score:  0.0\n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "\n",
    "clf_froest,y_pred_forest = train_model(RandomForestClassifier(n_estimators=10),X_train_new,y_train,X_test_new)\n",
    "evaluation_metric(y_test,y_pred_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
