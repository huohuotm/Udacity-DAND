{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/weidian1/Documents/GitHub/Udacity-DAND/P5-Intro to ML/Project5/final_project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "#sys.path.append(\"../pylof-master/\")\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "\n",
    "### Task 1: Select what features you'll use.\n",
    "### features_list is a list of strings, each of which is a feature name.\n",
    "### The first feature must be \"poi\".\n",
    "#features_list = ['poi','salary',''] # You will need to use more features\n",
    "\n",
    "### Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of data points:  145\n",
      "Number of POI: 18, no. of non-POI: 127\n",
      "Number of features used:  21\n"
     ]
    }
   ],
   "source": [
    "# 异常值， 去掉total\n",
    "def remove_outerliers(data_dict,names):\n",
    "    for name in names:\n",
    "        data_dict.pop(name, 0)\n",
    "    return data_dict\n",
    "\n",
    "def dateset_summary(data_dic):\n",
    "    n_poi,n_non_poi = 0,0\n",
    "    for key in data_dict.keys():\n",
    "        if data_dict[key]['poi']==1:\n",
    "            n_poi+=1\n",
    "        else:\n",
    "            n_non_poi+=1        \n",
    "    print \"Total number of data points: \", len(data_dict)\n",
    "    print \"Number of POI: %d, no. of non-POI: %d\"% (n_poi, n_non_poi)\n",
    "    print \"Number of features used: \",len(data_dict['METTS MARK']) # randomly pick one name, get the number of features.\n",
    "\n",
    "outliers_names = ['TOTAL']#,'LAVORATO JOHN J'\n",
    "\n",
    "data_dict = remove_outerliers(data_dict,outliers_names)\n",
    "dateset_summary(dateset_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-7e19ab192b26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mdata_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0memail_fatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNaNs_to_None\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data_df' is not defined"
     ]
    }
   ],
   "source": [
    "print data_df[email_fatures].apply(NaNs_to_None, axis=0).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "salary                        0\n",
      "to_messages                  59\n",
      "deferral_payments             0\n",
      "total_payments                0\n",
      "exercised_stock_options       0\n",
      "bonus                         0\n",
      "restricted_stock              0\n",
      "shared_receipt_with_poi      59\n",
      "restricted_stock_deferred     0\n",
      "total_stock_value             0\n",
      "expenses                      0\n",
      "loan_advances                 0\n",
      "from_messages                59\n",
      "other                         0\n",
      "from_this_person_to_poi      59\n",
      "poi                           0\n",
      "director_fees                 0\n",
      "deferred_income               0\n",
      "long_term_incentive           0\n",
      "email_address                34\n",
      "from_poi_to_this_person      59\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_df = pd.DataFrame.from_dict(data_dict,orient='index')\n",
    "\n",
    "financial_features = ['salary', 'deferral_payments', 'total_payments', 'loan_advances', 'bonus'\n",
    "                 , 'restricted_stock_deferred', 'deferred_income', 'total_stock_value', 'expenses'\n",
    "                 , 'exercised_stock_options', 'other', 'long_term_incentive', 'restricted_stock'\n",
    "                 , 'director_fees']\n",
    "email_fatures = ['to_messages','from_poi_to_this_person', 'from_messages', 'from_this_person_to_poi'\n",
    "                 , 'shared_receipt_with_poi']  # remove 'email_address'\n",
    "def NaNs_to_0s(col):\n",
    "    return [0 if ele=='NaN' else ele for ele in col]\n",
    "\n",
    "def NaNs_to_None(col):\n",
    "    return [None if ele=='NaN' else ele for ele in col]\n",
    "\n",
    "def count_NAN(col):\n",
    "    return sum(1 for ele in col if ele == 'NaN')\n",
    "\n",
    "data_df[financial_features] = data_df[financial_features].apply(NaNs_to_0s, axis=0)\n",
    "data_df['poi'] = data_df['poi'].astype(int)\n",
    "print data_df.apply(count_NAN, axis=0)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11bc7fdd0>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEaCAYAAAAsQ0GGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDw39+bI31sIyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11bcb1c10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "data_df.boxplot('bonus', by='poi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "make new feature \n",
    "1. 'email_features_miss': if email_features is missing. next step, missing email_features will be\n",
    "transformed to 0, which should by different from missing financial features.   \n",
    "2. poi_rate_to_messages = from_this_person_to_poi/to_messages  \n",
    "3. poi_rate_from_messages = from_poi_to_this_person/from_messages\n",
    "\n",
    "\"\"\"\n",
    "data_df['email_features_miss'] = data_df.apply(lambda x: 1 if x[\"to_messages\"]=='NaN' else 0, axis = 1)\n",
    "\n",
    "data_df['poi_rate_to_messages'] = data_df.apply(lambda x: 0 if x['from_this_person_to_poi']=='NaN' \\\n",
    "                                                else x['from_this_person_to_poi']*1.0/x['to_messages'], axis=1)\n",
    "\n",
    "data_df['poi_rate_from_messages'] = data_df.apply(lambda x: 0 if x['from_poi_to_this_person']=='NaN'\\\n",
    "                                                  else x['from_poi_to_this_person']*1.0/x['from_messages'], axis =1)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145, 21)\n",
      "['salary' 'to_messages' 'deferral_payments' 'total_payments'\n",
      " 'exercised_stock_options' 'bonus' 'restricted_stock'\n",
      " 'shared_receipt_with_poi' 'restricted_stock_deferred' 'total_stock_value'\n",
      " 'expenses' 'loan_advances' 'from_messages' 'other'\n",
      " 'from_this_person_to_poi' 'poi' 'director_fees' 'deferred_income'\n",
      " 'long_term_incentive' 'email_address' 'from_poi_to_this_person']\n"
     ]
    }
   ],
   "source": [
    "print data_df.shape#columns.values; 24个变量\n",
    "print data_df.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 这些新变量不要了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"create new features\n",
    "\"\"\"\n",
    "def get_new(col,p):\n",
    "    return (data_df[col].apply(abs)/(10**(p-1))%10).astype(int)\n",
    "def over_zero(ele):\n",
    "    if ele>0:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def add_new_features(df):\n",
    "    df[\"bonus_over_zero\"] = df['bonus'].apply(over_zero)\n",
    "    df[\"bonus_six\"] = get_new(\"bonus\",6)\n",
    "    df[\"bonus_seven\"] = get_new(\"bonus\",7)\n",
    "    \n",
    "    df[\"expenses_over_zero\"] = df[\"expenses\"].apply(over_zero)\n",
    "    df[\"expenses_five\"] = get_new(\"expenses\",5)\n",
    "    df[\"expenses_six\"] = get_new(\"expenses\",6)\n",
    "    \n",
    "    df[\"exercised_stock_options_over_zero\"] = df[\"exercised_stock_options\"].apply(over_zero)\n",
    "    df[\"exercised_stock_options_six\"] = get_new(\"exercised_stock_options\",6)\n",
    "    df[\"exercised_stock_options_seven\"] = get_new(\"exercised_stock_options\",7)\n",
    "    df[\"exercised_stock_options_eight\"] = get_new(\"exercised_stock_options\",8)\n",
    "    \n",
    "    df[\"salary_over_zero\"] = df[\"salary\"].apply(over_zero)\n",
    "    df[\"salary_six\"] = get_new(\"salary\",6)\n",
    "    df[\"salary_seven\"] = get_new(\"salary\",7)\n",
    "    \n",
    "    df[\"restricted_stock_over_zero\"] = df[\"restricted_stock\"].apply(over_zero)\n",
    "    df[\"restricted_stock_six\"] = get_new(\"restricted_stock\",6)\n",
    "    df[\"restricted_stock_seven\"] = get_new(\"restricted_stock\",7)\n",
    "    df[\"restricted_stock_eight\"] = get_new(\"restricted_stock\",8)\n",
    "    \n",
    "    df[\"deferred_income_over_zero\"] = df[\"deferred_income\"].apply(over_zero)\n",
    "    df[\"deferred_income_five\"] = get_new(\"deferred_income\",5)\n",
    "    df[\"deferred_income_six\"] = get_new(\"deferred_income\",6)\n",
    "    df[\"deferred_income_seven\"] = get_new(\"deferred_income\",7)\n",
    "    \n",
    "    df[\"other_over_zero\"] = df[\"other\"].apply(over_zero)\n",
    "    df[\"other_six\"] = get_new(\"other\",6)\n",
    "    df[\"other_seven\"] = get_new(\"other\",7)\n",
    "    df[\"other_eight\"] = get_new(\"other\",8)\n",
    "    return df\n",
    "\n",
    "data_df = add_new_features(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get mydata(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 full_columns_name: ['poi', 'salary', 'to_messages', 'deferral_payments', 'total_payments', 'exercised_stock_options', 'bonus', 'restricted_stock', 'shared_receipt_with_poi', 'restricted_stock_deferred', 'total_stock_value', 'expenses', 'loan_advances', 'from_messages', 'other', 'from_this_person_to_poi', 'director_fees', 'deferred_income', 'long_term_incentive', 'from_poi_to_this_person']\n"
     ]
    }
   ],
   "source": [
    "features_full_list = list(data_df.columns.values)\n",
    "features_full_list.remove('email_address')\n",
    "features_full_list.remove('poi')\n",
    "features_full_list = ['poi'] +features_full_list\n",
    "data_full_dic = data_df.to_dict(orient='index')\n",
    "print (\"%d full_columns_name: %s\" % (len(features_full_list), features_full_list))\n",
    "\n",
    "#def get_train_test_dataset(my_dataset,features_list):\n",
    "#    #Extract features and labels from dataset for local testing\n",
    "#    data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "#    labels, features = targetFeatureSplit(data)\n",
    "#    # TODO: Shuffle the data\n",
    "#    from sklearn.utils import shuffle\n",
    "#    features, labels = shuffle(features, labels, random_state=1)\n",
    "#    \n",
    "#    # split train test dataset\n",
    "#    from sklearn.model_selection import train_test_split\n",
    "#    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "#    X_train = np.array(X_train)\n",
    "#    y_train = np.array(y_train)\n",
    "#    X_test = np.array(X_test)\n",
    "#    y_test = np.array(y_test)\n",
    "#    \n",
    "#    return X_train, X_test, y_train, y_test\n",
    "#    \n",
    "#X_train, X_test, y_train, y_test = get_train_test_dataset(data_full_dic,features_full_list)  \n",
    "    \n",
    "def get_features_labels(my_dataset,features_list):\n",
    "    #Extract features and labels from dataset for local testing\n",
    "    data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "    labels, features = targetFeatureSplit(data)\n",
    "    # TODO: Shuffle the data\n",
    "    from sklearn.utils import shuffle\n",
    "    features, labels = shuffle(features, labels, random_state=1)\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "    return features, labels\n",
    "\n",
    "def get_train_test_dataset(features, labels):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "  \n",
    "features, labels = get_features_labels(data_full_dic,features_full_list)\n",
    "X_train, X_test, y_train, y_test = get_train_test_dataset(features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "min_max_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train_scaled = min_max_scaler.fit_transform(X_train)\n",
    "X_test_scaled = min_max_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## select features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "select important features \n",
    "\"\"\"\n",
    "def select_features(X_train,y_train,X_test, method='tree',k=None):\n",
    "    from sklearn.utils import shuffle\n",
    "    X_train, y_train = shuffle(X_train, y_train, random_state=0)\n",
    "    if method == 'tree':\n",
    "        \n",
    "        from sklearn.ensemble import ExtraTreesClassifier\n",
    "        from sklearn.feature_selection import SelectFromModel   \n",
    "\n",
    "        selection_tree = ExtraTreesClassifier(random_state=32)\n",
    "        selection_tree = selection_tree.fit(X_train, y_train)\n",
    "\n",
    "        model_tree = SelectFromModel(selection_tree, prefit=True)\n",
    "        X_train_new = model_tree.transform(X_train)\n",
    "        X_test_new = model_tree.transform(X_test)\n",
    "        \n",
    "        print \"shape of X_train: \", X_train.shape\n",
    "        print \"shape of X_train_new: \", X_train_new.shape    \n",
    "        return selection_tree,X_train_new,X_test_new\n",
    "    \n",
    "    elif method == 'kbest' and k:\n",
    "        from sklearn.feature_selection import SelectKBest\n",
    "        from sklearn.feature_selection import f_classif\n",
    "\n",
    "        selection_k= SelectKBest(f_classif, k=k).fit(X_train, y_train)\n",
    "        X_train_new = selection_k.transform(X_train)\n",
    "        X_test_new = selection_k.transform(X_test)\n",
    "        print \"shape of X_train: \", X_train.shape\n",
    "        print \"shape of X_train_new: \", X_train_new.shape   \n",
    "        return selection_k,X_train_new,X_test_new\n",
    "        \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#selection_tree,X_train_new,X_test_new = select_features(X_train_scaled,y_train,X_test_scaled)\n",
    "X_train_new,X_test_new = X_train_scaled,X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X_train:  (101, 22)\n",
      "shape of X_train_new:  (101, 10)\n"
     ]
    }
   ],
   "source": [
    "selection_k,X_train_new,X_test_new = select_features(X_train_scaled,y_train,X_test_scaled,method='kbest',k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def train_model(classifier,features_train,labels_train,features_test):\n",
    "    clf = classifier\n",
    "    clf.fit(features_train, labels_train)\n",
    "    labels_pred = clf.predict(features_test)\n",
    "    return clf,labels_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluation_metric(labels_test,labels_pred):\n",
    "    from sklearn.metrics import recall_score\n",
    "    from sklearn.metrics import precision_score\n",
    "    from sklearn.metrics import f1_score\n",
    "    \n",
    "    print \"recall_score: \",recall_score(y_test, labels_pred)\n",
    "    print \"precision_score: \",precision_score(labels_test, labels_pred)  \n",
    "    print \"f1_score: \",f1_score(labels_test, labels_pred)  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用tree 的到的features，建模，问题\n",
    "navie bayers 和 decision tree 完全反的;    \n",
    "SVM，randomforest 出现no TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_score:  0.444444444444\n",
      "precision_score:  0.5\n",
      "f1_score:  0.470588235294\n"
     ]
    }
   ],
   "source": [
    "# naive bayers\n",
    "clf_nb,y_pred_nb = train_model(GaussianNB(),X_train,y_train,X_test)\n",
    "evaluation_metric(y_test,y_pred_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_score:  0.666666666667\n",
      "precision_score:  0.214285714286\n",
      "f1_score:  0.324324324324\n"
     ]
    }
   ],
   "source": [
    "clf_nb,y_pred_nb = train_model(GaussianNB(),X_train_scaled,y_train,X_test_scaled)\n",
    "evaluation_metric(y_test,y_pred_nb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_score:  0.0\n",
      "precision_score:  0.0\n",
      "f1_score:  0.0\n"
     ]
    }
   ],
   "source": [
    "#svm\n",
    "clf_svm,y_pred_svm = train_model(SVC(),X_train_new,y_train,X_test_new)\n",
    "evaluation_metric(y_test,y_pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_score:  0.111111111111\n",
      "precision_score:  0.25\n",
      "f1_score:  0.153846153846\n"
     ]
    }
   ],
   "source": [
    "# decision tree\n",
    "clf_dtree,y_pred_stree = train_model(tree.DecisionTreeClassifier(),X_train_new,y_train,X_test_new)\n",
    "evaluation_metric(y_test,y_pred_stree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_score:  0.0\n",
      "precision_score:  0.0\n",
      "f1_score:  0.0\n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "\n",
    "clf_froest,y_pred_forest = train_model(RandomForestClassifier(n_estimators=10),X_train_new,y_train,X_test_new)\n",
    "evaluation_metric(y_test,y_pred_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kbest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_score:  0.666666666667\n",
      "precision_score:  0.285714285714\n",
      "f1_score:  0.4\n"
     ]
    }
   ],
   "source": [
    "# naive bayers\n",
    "clf_nb,y_pred_nb = train_model(GaussianNB(),X_train_new,y_train,X_test_new)\n",
    "evaluation_metric(y_test,y_pred_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_score:  0.0\n",
      "precision_score:  0.0\n",
      "f1_score:  0.0\n"
     ]
    }
   ],
   "source": [
    "#svm\n",
    "clf_svm,y_pred_svm = train_model(SVC(),X_train_new,y_train,X_test_new)\n",
    "evaluation_metric(y_test,y_pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_score:  0.0\n",
      "precision_score:  0.0\n",
      "f1_score:  0.0\n"
     ]
    }
   ],
   "source": [
    "# decision tree\n",
    "clf_dtree,y_pred_stree = train_model(tree.DecisionTreeClassifier(),X_train_new,y_train,X_test_new)\n",
    "evaluation_metric(y_test,y_pred_stree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_score:  0.0\n",
      "precision_score:  0.0\n",
      "f1_score:  0.0\n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "\n",
    "clf_froest,y_pred_forest = train_model(RandomForestClassifier(n_estimators=10),X_train_new,y_train,X_test_new)\n",
    "evaluation_metric(y_test,y_pred_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipiline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "estimators = [('reduce_dim', PCA()), ('clf', SVC())]\n",
    "pipe = Pipeline(estimators)\n",
    "pipe \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "params = dict(reduce_dim__n_components=[2, 5, 10],\n",
    "              clf__C=[0.1, 10, 100])\n",
    "grid_search = GridSearchCV(pipe, param_grid=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "params = dict(reduce_dim=[None, PCA(5), PCA(10)],\n",
    "              clf=[SVC(), LogisticRegression()],\n",
    "              clf__C=[0.1, 10, 100])\n",
    "grid_search = GridSearchCV(pipe, param_grid=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy import mean,std\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel \n",
    "\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "\n",
    "def scorer_r_p(estimator, X_test, y_test):\n",
    "    y_pred = estimator.predict(X_test)\n",
    "    r_score = recall_score(y_test, y_pred)\n",
    "    p_score = precision_score(y_test, y_pred)\n",
    "#    f1_score = f1_score(y_test, y_pred)\n",
    "    if r_score<0.3 or p_score<0.3:\n",
    "        return 0    \n",
    "    return r_score + p_score\n",
    "\n",
    "\n",
    "class EstimatorSelectionHelper:\n",
    "    def __init__(self, models, params):\n",
    "        if not set(models.keys()).issubset(set(params.keys())):\n",
    "            missing_params = list(set(models.keys()) - set(params.keys()))\n",
    "            raise ValueError(\"Some estimators are missing parameters: %s\" % missing_params)\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "        \n",
    "        min_max_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        model_tree = SelectFromModel(ExtraTreesClassifier(random_state=32), prefit=False)\n",
    "        preparation = [('scaler',min_max_scaler)\n",
    "                      ,('selector',model_tree)]\n",
    "        params_selector ={'selector__threshold':['mean','0.5*mean','1.4*mean'] }\n",
    "        self.preparation = preparation\n",
    "        self.scores_df = None\n",
    "\n",
    "    def fit(self, X, y, cv=3, n_jobs=1, verbose=1, scoring=None, refit=True):\n",
    "        for key in self.keys:\n",
    "            print(\"Running GridSearchCV for %s.\" % key)\n",
    "            model = self.models[key]\n",
    "            #params = self.params[key]\n",
    "            if isinstance(self.params[key],list):\n",
    "                params = [dict(param.items() + params_selector.items()) for param in self.params[key]]           \n",
    "            elif isinstance(self.params[key],dict):\n",
    "                params = dict(self.params[key].items() + params_selector.items())\n",
    "            preparation = self.preparation\n",
    "            pipe= Pipeline(preparation +[(key,model)])        \n",
    "            gs = GridSearchCV(pipe, params, cv=cv, n_jobs=n_jobs,verbose=verbose, scoring=scoring, refit=refit)\n",
    "            gs.fit(X,y)\n",
    "            self.grid_searches[key] = gs    \n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                 'estimator': key,\n",
    "                 'min_score': min(scores),\n",
    "                 'max_score': max(scores),\n",
    "                 'mean_score': mean(scores),\n",
    "                 'std_score': std(scores),\n",
    "            }\n",
    "            return pd.Series(dict(params.items() + d.items()))\n",
    "\n",
    "        rows = [row(k, gsc.cv_validation_scores, gsc.parameters) \n",
    "                     for k in self.keys\n",
    "                     for gsc in self.grid_searches[k].grid_scores_]\n",
    "        df = pd.concat(rows, axis=1).T.sort_values(by=[sort_by], ascending=False)\n",
    "\n",
    "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "        self.scores_df = df[columns]\n",
    "        return df[columns]\n",
    "    \n",
    "    def best_estimator_model(self):\n",
    "        if  isinstance(self.scores_df,pd.DataFrame):\n",
    "            model_name = self.scores_df.iloc[0,0]\n",
    "            best_estimator_ = self.grid_searches[model_name].best_estimator_\n",
    "            best_model = self.grid_searches[model_name].best_estimator_.steps[-1][-1]\n",
    "            return best_estimator_, best_model       \n",
    "        else:\n",
    "            raise ValueError('scores_df is None; run fit() and score_summary() first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for AdaBoostClassifier.\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   13.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for GradientBoostingClassifier.\n",
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  80 tasks      | elapsed:    3.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for ExtraTreesClassifier.\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:   13.1s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   17.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for RandomForestClassifier.\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   19.5s finished\n"
     ]
    }
   ],
   "source": [
    "models1 = { \n",
    "    'ExtraTreesClassifier': ExtraTreesClassifier(),\n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'AdaBoostClassifier': AdaBoostClassifier(),\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier()\n",
    "    #'SVC': SVC()\n",
    "}\n",
    "\n",
    "params1 = { \n",
    "    'ExtraTreesClassifier': { 'ExtraTreesClassifier__n_estimators': [16, 32, 50, 100] },\n",
    "    'RandomForestClassifier': { 'RandomForestClassifier__n_estimators': [16, 32, 50, 100] },\n",
    "    'AdaBoostClassifier':  { 'AdaBoostClassifier__n_estimators': [16, 32, 50, 100] },\n",
    "    'GradientBoostingClassifier': { 'GradientBoostingClassifier__n_estimators': [16, 32, 50, 100]\n",
    "                                   , 'GradientBoostingClassifier__learning_rate': [0.5, 0.8, 1.0] }\n",
    "    #'SVC': [\n",
    "    #    {'SVC__kernel': ['linear'], 'SVC__C': [1, 10]},\n",
    "    #    {'SVC__kernel': ['rbf'], 'SVC__C': [1, 10], 'SVC__gamma': [0.001, 0.0001]},\n",
    "    #]\n",
    "}\n",
    "\n",
    "helper1 = EstimatorSelectionHelper(models1, params1)\n",
    "helper1.fit(features, labels,cv=10, scoring='recall', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model:  GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.5, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=32, presort='auto', random_state=None,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "scores_df1 = helper1.score_summary()\n",
    "#scores_df.iloc[0,0]\n",
    "best_estimator_1,best_model1 = helper1.best_estimator_model()\n",
    "print \"best model: \",best_model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>AdaBoostClassifier__n_estimators</th>\n",
       "      <th>ExtraTreesClassifier__n_estimators</th>\n",
       "      <th>GradientBoostingClassifier__learning_rate</th>\n",
       "      <th>GradientBoostingClassifier__n_estimators</th>\n",
       "      <th>RandomForestClassifier__n_estimators</th>\n",
       "      <th>selector__threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1</td>\n",
       "      <td>0.415331</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.4*mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.415331</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.4*mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.43589</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5*mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.43589</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5*mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.43589</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.4*mean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     estimator min_score mean_score max_score std_score  \\\n",
       "17  GradientBoostingClassifier         0       0.55         1  0.415331   \n",
       "8           AdaBoostClassifier         0       0.45         1  0.415331   \n",
       "40  GradientBoostingClassifier         0        0.4         1   0.43589   \n",
       "43  GradientBoostingClassifier         0        0.4         1   0.43589   \n",
       "47  GradientBoostingClassifier         0        0.4         1   0.43589   \n",
       "\n",
       "   AdaBoostClassifier__n_estimators ExtraTreesClassifier__n_estimators  \\\n",
       "17                              NaN                                NaN   \n",
       "8                                50                                NaN   \n",
       "40                              NaN                                NaN   \n",
       "43                              NaN                                NaN   \n",
       "47                              NaN                                NaN   \n",
       "\n",
       "   GradientBoostingClassifier__learning_rate  \\\n",
       "17                                       0.5   \n",
       "8                                        NaN   \n",
       "40                                         1   \n",
       "43                                         1   \n",
       "47                                         1   \n",
       "\n",
       "   GradientBoostingClassifier__n_estimators  \\\n",
       "17                                       32   \n",
       "8                                       NaN   \n",
       "40                                       32   \n",
       "43                                       50   \n",
       "47                                      100   \n",
       "\n",
       "   RandomForestClassifier__n_estimators selector__threshold  \n",
       "17                                  NaN            1.4*mean  \n",
       "8                                   NaN            1.4*mean  \n",
       "40                                  NaN            0.5*mean  \n",
       "43                                  NaN            0.5*mean  \n",
       "47                                  NaN            1.4*mean  "
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df1.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for AdaBoostClassifier.\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   13.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for GradientBoostingClassifier.\n",
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:   15.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for ExtraTreesClassifier.\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   15.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for RandomForestClassifier.\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   15.2s finished\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "scores_df is None; run fit() and score_summary() first",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-380-303d3402c1c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mhelper2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mscores_df2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhelper1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mbest_estimator_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_model2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhelper2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"best model: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_model2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mscores_df2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-329-986a84c8c685>\u001b[0m in \u001b[0;36mbest_estimator_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mbest_estimator_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'scores_df is None; run fit() and score_summary() first'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: scores_df is None; run fit() and score_summary() first"
     ]
    }
   ],
   "source": [
    "helper2 = EstimatorSelectionHelper(models1, params1)\n",
    "helper2.fit(features, labels,cv=10, scoring='precision', n_jobs=-1)\n",
    "scores_df2 = helper2.score_summary()\n",
    "best_estimator_2,best_model2 = helper2.best_estimator_model()\n",
    "print \"best model: \",best_model2\n",
    "scores_df2.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model:  GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.5, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=32, presort='auto', random_state=None,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>AdaBoostClassifier__n_estimators</th>\n",
       "      <th>ExtraTreesClassifier__n_estimators</th>\n",
       "      <th>GradientBoostingClassifier__learning_rate</th>\n",
       "      <th>GradientBoostingClassifier__n_estimators</th>\n",
       "      <th>RandomForestClassifier__n_estimators</th>\n",
       "      <th>selector__threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.363624</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.4*mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.416333</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.442531</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.4*mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.381881</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.4*mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.37305</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     estimator min_score mean_score max_score std_score  \\\n",
       "17  GradientBoostingClassifier         0   0.466667         1  0.363624   \n",
       "9           AdaBoostClassifier         0   0.433333         1  0.416333   \n",
       "5           AdaBoostClassifier         0   0.416667         1  0.442531   \n",
       "8           AdaBoostClassifier         0   0.416667         1  0.381881   \n",
       "6           AdaBoostClassifier         0   0.383333         1   0.37305   \n",
       "\n",
       "   AdaBoostClassifier__n_estimators ExtraTreesClassifier__n_estimators  \\\n",
       "17                              NaN                                NaN   \n",
       "9                               100                                NaN   \n",
       "5                                32                                NaN   \n",
       "8                                50                                NaN   \n",
       "6                                50                                NaN   \n",
       "\n",
       "   GradientBoostingClassifier__learning_rate  \\\n",
       "17                                       0.5   \n",
       "9                                        NaN   \n",
       "5                                        NaN   \n",
       "8                                        NaN   \n",
       "6                                        NaN   \n",
       "\n",
       "   GradientBoostingClassifier__n_estimators  \\\n",
       "17                                       32   \n",
       "9                                       NaN   \n",
       "5                                       NaN   \n",
       "8                                       NaN   \n",
       "6                                       NaN   \n",
       "\n",
       "   RandomForestClassifier__n_estimators selector__threshold  \n",
       "17                                  NaN            1.4*mean  \n",
       "9                                   NaN                mean  \n",
       "5                                   NaN            1.4*mean  \n",
       "8                                   NaN            1.4*mean  \n",
       "6                                   NaN                mean  "
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df2 = helper2.score_summary()\n",
    "best_estimator_2,best_model2 = helper2.best_estimator_model()\n",
    "print \"best model: \",best_model2\n",
    "scores_df2.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaler MinMaxScaler(copy=True, feature_range=(0, 1))\n",
      "selector SelectFromModel(estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=10, n_jobs=1, oob_score=False, random_state=32,\n",
      "           verbose=0, warm_start=False),\n",
      "        prefit=False, threshold='mean')\n",
      "AdaBoostClassifier AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None)\n"
     ]
    }
   ],
   "source": [
    "for step in best_estimator_.steps:\n",
    "    print step[0],step[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=10, n_jobs=1, oob_score=False, random_state=32,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = best_estimator_.steps[1][-1].estimator_\n",
    "forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('selector', SelectFromModel(estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_le...m='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None))])"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 13 (0.111528)\n",
      "2. feature 16 (0.101880)\n",
      "3. feature 6 (0.080032)\n",
      "4. feature 5 (0.075923)\n",
      "5. feature 9 (0.068396)\n",
      "6. feature 0 (0.067129)\n",
      "7. feature 18 (0.061514)\n",
      "8. feature 4 (0.060429)\n",
      "9. feature 3 (0.059110)\n",
      "10. feature 7 (0.056590)\n",
      "11. feature 14 (0.055999)\n",
      "12. feature 1 (0.047120)\n",
      "13. feature 17 (0.035974)\n",
      "14. feature 12 (0.034962)\n",
      "15. feature 10 (0.029403)\n",
      "16. feature 11 (0.028566)\n",
      "17. feature 2 (0.022958)\n",
      "18. feature 15 (0.001599)\n",
      "19. feature 8 (0.000886)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEKCAYAAADpfBXhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11bed12d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "forest.fit(X_train_scaled , y_train)\n",
    "importances = forest.feature_importances_\n",
    "#std = np.std([tree.feature_importances_ for tree in forest.estimators_],axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X_train_scaled .shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X_train_scaled.shape[1]), importances[indices],color=\"r\")#, yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X_train_scaled.shape[1]), indices)\n",
    "plt.xlim([-1, X_train_scaled.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13, 16,  6,  5,  9,  0, 18,  4,  3,  7, 14,  1, 17, 12, 10, 11,  2,\n",
       "       15,  8])"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.06712889,  0.04712015,  0.02295805,  0.05911037,  0.06042886,\n",
       "        0.07592324,  0.08003241,  0.05659005,  0.00088592,  0.06839614,\n",
       "        0.02940319,  0.0285665 ,  0.03496242,  0.11152839,  0.05599861,\n",
       "        0.00159874,  0.10188032,  0.03597353,  0.06151426])"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.052631578947368418"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean(importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6:\n",
    "Dump your classifier, dataset, and features_list so anyone can\n",
    "check your results. You do not need to change anything below, but make sure that the version of poi_id.py that you submit can be run on its own and generates the necessary .pkl files for validating your results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tester import dump_classifier_and_data\n",
    "#clf = GaussianNB()#best_estimator_\n",
    "#features_list = [features_full_list[1:][index] for index,importance in enumerate(importances) if importance>=1.4*mean(importances)]\n",
    "#features_list = ['poi']+features_list\n",
    "features_list = features_full_list\n",
    "my_dataset = data_full_dic\n",
    "\n",
    "clf = best_estimator_2\n",
    "#clf = Pipeline(steps=[('scaler',MinMaxScaler(copy=True, feature_range=(0, 1)))\n",
    "#                      ,('classifier', RandomForestClassifier(n_estimators=100,min_samples_split=4,max_features=3))])\n",
    "\n",
    "dump_classifier_and_data(clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
       " ('selector',\n",
       "  SelectFromModel(estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=10, n_jobs=1, oob_score=False, random_state=32,\n",
       "             verbose=0, warm_start=False),\n",
       "          prefit=False, threshold='1.4*mean')),\n",
       " ('GradientBoostingClassifier',\n",
       "  GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "                learning_rate=0.5, loss='deviance', max_depth=3,\n",
       "                max_features=None, max_leaf_nodes=None,\n",
       "                min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "                min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                n_estimators=32, presort='auto', random_state=None,\n",
       "                subsample=1.0, verbose=0, warm_start=False))]"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimator_2.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.022727272727272724"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Running GridSearchCV for GaussianNB.------\n",
      "[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('GaussianNB', GaussianNB(priors=None))]\n",
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('GaussianNB', GaussianNB(priors=None))])\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "------Running GridSearchCV for AdaBoostClassifier.------\n",
      "[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('AdaBoostClassifier', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None))]\n",
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('AdaBoostClassifier', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None))])\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Running GridSearchCV for GradientBoostingClassifier.------\n",
      "[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('GradientBoostingClassifier', GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=None,\n",
      "              subsample=1.0, verbose=0, warm_start=False))]\n",
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('GradientBoostingClassifier', GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impu...=100, presort='auto', random_state=None,\n",
      "              subsample=1.0, verbose=0, warm_start=False))])\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Running GridSearchCV for RandomForestClassifier.------\n",
      "[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('RandomForestClassifier', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False))]\n",
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('RandomForestClassifier', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False))])\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "                    estimators mean_score  min_score max_score  std_score  \\\n",
      "0                   GaussianNB   0.161905  0.0952381       0.2  0.0473005   \n",
      "1                   GaussianNB    0.15873  0.0952381  0.190476  0.0448957   \n",
      "2           AdaBoostClassifier   0.133333          0       0.4   0.188562   \n",
      "32      RandomForestClassifier          0          0         0          0   \n",
      "24      RandomForestClassifier          0          0         0          0   \n",
      "25      RandomForestClassifier          0          0         0          0   \n",
      "26      RandomForestClassifier          0          0         0          0   \n",
      "27      RandomForestClassifier          0          0         0          0   \n",
      "28      RandomForestClassifier          0          0         0          0   \n",
      "29      RandomForestClassifier          0          0         0          0   \n",
      "30      RandomForestClassifier          0          0         0          0   \n",
      "31      RandomForestClassifier          0          0         0          0   \n",
      "33      RandomForestClassifier          0          0         0          0   \n",
      "42      RandomForestClassifier          0          0         0          0   \n",
      "23      RandomForestClassifier          0          0         0          0   \n",
      "35      RandomForestClassifier          0          0         0          0   \n",
      "36      RandomForestClassifier          0          0         0          0   \n",
      "37      RandomForestClassifier          0          0         0          0   \n",
      "38      RandomForestClassifier          0          0         0          0   \n",
      "39      RandomForestClassifier          0          0         0          0   \n",
      "40      RandomForestClassifier          0          0         0          0   \n",
      "41      RandomForestClassifier          0          0         0          0   \n",
      "34      RandomForestClassifier          0          0         0          0   \n",
      "22      RandomForestClassifier          0          0         0          0   \n",
      "21      RandomForestClassifier          0          0         0          0   \n",
      "20      RandomForestClassifier          0          0         0          0   \n",
      "3           AdaBoostClassifier          0          0         0          0   \n",
      "4   GradientBoostingClassifier          0          0         0          0   \n",
      "5   GradientBoostingClassifier          0          0         0          0   \n",
      "6   GradientBoostingClassifier          0          0         0          0   \n",
      "7   GradientBoostingClassifier          0          0         0          0   \n",
      "8       RandomForestClassifier          0          0         0          0   \n",
      "9       RandomForestClassifier          0          0         0          0   \n",
      "10      RandomForestClassifier          0          0         0          0   \n",
      "11      RandomForestClassifier          0          0         0          0   \n",
      "12      RandomForestClassifier          0          0         0          0   \n",
      "13      RandomForestClassifier          0          0         0          0   \n",
      "14      RandomForestClassifier          0          0         0          0   \n",
      "15      RandomForestClassifier          0          0         0          0   \n",
      "16      RandomForestClassifier          0          0         0          0   \n",
      "17      RandomForestClassifier          0          0         0          0   \n",
      "18      RandomForestClassifier          0          0         0          0   \n",
      "19      RandomForestClassifier          0          0         0          0   \n",
      "43      RandomForestClassifier          0          0         0          0   \n",
      "\n",
      "   AdaBoostClassifier__n_estimators GaussianNB__priors  \\\n",
      "0                               NaN               None   \n",
      "1                               NaN     [0.124, 0.876]   \n",
      "2                                16                NaN   \n",
      "32                              NaN                NaN   \n",
      "24                              NaN                NaN   \n",
      "25                              NaN                NaN   \n",
      "26                              NaN                NaN   \n",
      "27                              NaN                NaN   \n",
      "28                              NaN                NaN   \n",
      "29                              NaN                NaN   \n",
      "30                              NaN                NaN   \n",
      "31                              NaN                NaN   \n",
      "33                              NaN                NaN   \n",
      "42                              NaN                NaN   \n",
      "23                              NaN                NaN   \n",
      "35                              NaN                NaN   \n",
      "36                              NaN                NaN   \n",
      "37                              NaN                NaN   \n",
      "38                              NaN                NaN   \n",
      "39                              NaN                NaN   \n",
      "40                              NaN                NaN   \n",
      "41                              NaN                NaN   \n",
      "34                              NaN                NaN   \n",
      "22                              NaN                NaN   \n",
      "21                              NaN                NaN   \n",
      "20                              NaN                NaN   \n",
      "3                                32                NaN   \n",
      "4                               NaN                NaN   \n",
      "5                               NaN                NaN   \n",
      "6                               NaN                NaN   \n",
      "7                               NaN                NaN   \n",
      "8                               NaN                NaN   \n",
      "9                               NaN                NaN   \n",
      "10                              NaN                NaN   \n",
      "11                              NaN                NaN   \n",
      "12                              NaN                NaN   \n",
      "13                              NaN                NaN   \n",
      "14                              NaN                NaN   \n",
      "15                              NaN                NaN   \n",
      "16                              NaN                NaN   \n",
      "17                              NaN                NaN   \n",
      "18                              NaN                NaN   \n",
      "19                              NaN                NaN   \n",
      "43                              NaN                NaN   \n",
      "\n",
      "   GradientBoostingClassifier__learning_rate  \\\n",
      "0                                        NaN   \n",
      "1                                        NaN   \n",
      "2                                        NaN   \n",
      "32                                       NaN   \n",
      "24                                       NaN   \n",
      "25                                       NaN   \n",
      "26                                       NaN   \n",
      "27                                       NaN   \n",
      "28                                       NaN   \n",
      "29                                       NaN   \n",
      "30                                       NaN   \n",
      "31                                       NaN   \n",
      "33                                       NaN   \n",
      "42                                       NaN   \n",
      "23                                       NaN   \n",
      "35                                       NaN   \n",
      "36                                       NaN   \n",
      "37                                       NaN   \n",
      "38                                       NaN   \n",
      "39                                       NaN   \n",
      "40                                       NaN   \n",
      "41                                       NaN   \n",
      "34                                       NaN   \n",
      "22                                       NaN   \n",
      "21                                       NaN   \n",
      "20                                       NaN   \n",
      "3                                        NaN   \n",
      "4                                        0.8   \n",
      "5                                        0.8   \n",
      "6                                          1   \n",
      "7                                          1   \n",
      "8                                        NaN   \n",
      "9                                        NaN   \n",
      "10                                       NaN   \n",
      "11                                       NaN   \n",
      "12                                       NaN   \n",
      "13                                       NaN   \n",
      "14                                       NaN   \n",
      "15                                       NaN   \n",
      "16                                       NaN   \n",
      "17                                       NaN   \n",
      "18                                       NaN   \n",
      "19                                       NaN   \n",
      "43                                       NaN   \n",
      "\n",
      "   GradientBoostingClassifier__n_estimators  \\\n",
      "0                                       NaN   \n",
      "1                                       NaN   \n",
      "2                                       NaN   \n",
      "32                                      NaN   \n",
      "24                                      NaN   \n",
      "25                                      NaN   \n",
      "26                                      NaN   \n",
      "27                                      NaN   \n",
      "28                                      NaN   \n",
      "29                                      NaN   \n",
      "30                                      NaN   \n",
      "31                                      NaN   \n",
      "33                                      NaN   \n",
      "42                                      NaN   \n",
      "23                                      NaN   \n",
      "35                                      NaN   \n",
      "36                                      NaN   \n",
      "37                                      NaN   \n",
      "38                                      NaN   \n",
      "39                                      NaN   \n",
      "40                                      NaN   \n",
      "41                                      NaN   \n",
      "34                                      NaN   \n",
      "22                                      NaN   \n",
      "21                                      NaN   \n",
      "20                                      NaN   \n",
      "3                                       NaN   \n",
      "4                                        16   \n",
      "5                                        32   \n",
      "6                                        16   \n",
      "7                                        32   \n",
      "8                                       NaN   \n",
      "9                                       NaN   \n",
      "10                                      NaN   \n",
      "11                                      NaN   \n",
      "12                                      NaN   \n",
      "13                                      NaN   \n",
      "14                                      NaN   \n",
      "15                                      NaN   \n",
      "16                                      NaN   \n",
      "17                                      NaN   \n",
      "18                                      NaN   \n",
      "19                                      NaN   \n",
      "43                                      NaN   \n",
      "\n",
      "   RandomForestClassifier__max_features  \\\n",
      "0                                   NaN   \n",
      "1                                   NaN   \n",
      "2                                   NaN   \n",
      "32                                    5   \n",
      "24                                    4   \n",
      "25                                    4   \n",
      "26                                    4   \n",
      "27                                    4   \n",
      "28                                    4   \n",
      "29                                    4   \n",
      "30                                    4   \n",
      "31                                    4   \n",
      "33                                    5   \n",
      "42                                    5   \n",
      "23                                    4   \n",
      "35                                    5   \n",
      "36                                    5   \n",
      "37                                    5   \n",
      "38                                    5   \n",
      "39                                    5   \n",
      "40                                    5   \n",
      "41                                    5   \n",
      "34                                    5   \n",
      "22                                    4   \n",
      "21                                    4   \n",
      "20                                    4   \n",
      "3                                   NaN   \n",
      "4                                   NaN   \n",
      "5                                   NaN   \n",
      "6                                   NaN   \n",
      "7                                   NaN   \n",
      "8                                     3   \n",
      "9                                     3   \n",
      "10                                    3   \n",
      "11                                    3   \n",
      "12                                    3   \n",
      "13                                    3   \n",
      "14                                    3   \n",
      "15                                    3   \n",
      "16                                    3   \n",
      "17                                    3   \n",
      "18                                    3   \n",
      "19                                    3   \n",
      "43                                    5   \n",
      "\n",
      "   RandomForestClassifier__min_samples_split  \\\n",
      "0                                        NaN   \n",
      "1                                        NaN   \n",
      "2                                        NaN   \n",
      "32                                         2   \n",
      "24                                         3   \n",
      "25                                         3   \n",
      "26                                         3   \n",
      "27                                         3   \n",
      "28                                         4   \n",
      "29                                         4   \n",
      "30                                         4   \n",
      "31                                         4   \n",
      "33                                         2   \n",
      "42                                         4   \n",
      "23                                         2   \n",
      "35                                         2   \n",
      "36                                         3   \n",
      "37                                         3   \n",
      "38                                         3   \n",
      "39                                         3   \n",
      "40                                         4   \n",
      "41                                         4   \n",
      "34                                         2   \n",
      "22                                         2   \n",
      "21                                         2   \n",
      "20                                         2   \n",
      "3                                        NaN   \n",
      "4                                        NaN   \n",
      "5                                        NaN   \n",
      "6                                        NaN   \n",
      "7                                        NaN   \n",
      "8                                          2   \n",
      "9                                          2   \n",
      "10                                         2   \n",
      "11                                         2   \n",
      "12                                         3   \n",
      "13                                         3   \n",
      "14                                         3   \n",
      "15                                         3   \n",
      "16                                         4   \n",
      "17                                         4   \n",
      "18                                         4   \n",
      "19                                         4   \n",
      "43                                         4   \n",
      "\n",
      "   RandomForestClassifier__n_estimators  \n",
      "0                                   NaN  \n",
      "1                                   NaN  \n",
      "2                                   NaN  \n",
      "32                                   16  \n",
      "24                                   16  \n",
      "25                                   32  \n",
      "26                                   50  \n",
      "27                                  100  \n",
      "28                                   16  \n",
      "29                                   32  \n",
      "30                                   50  \n",
      "31                                  100  \n",
      "33                                   32  \n",
      "42                                   50  \n",
      "23                                  100  \n",
      "35                                  100  \n",
      "36                                   16  \n",
      "37                                   32  \n",
      "38                                   50  \n",
      "39                                  100  \n",
      "40                                   16  \n",
      "41                                   32  \n",
      "34                                   50  \n",
      "22                                   50  \n",
      "21                                   32  \n",
      "20                                   16  \n",
      "3                                   NaN  \n",
      "4                                   NaN  \n",
      "5                                   NaN  \n",
      "6                                   NaN  \n",
      "7                                   NaN  \n",
      "8                                    16  \n",
      "9                                    32  \n",
      "10                                   50  \n",
      "11                                  100  \n",
      "12                                   16  \n",
      "13                                   32  \n",
      "14                                   50  \n",
      "15                                  100  \n",
      "16                                   16  \n",
      "17                                   32  \n",
      "18                                   50  \n",
      "19                                  100  \n",
      "43                                  100  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 108 out of 108 | elapsed:   25.5s finished\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from numpy import mean,std\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import (ExtraTreesClassifier, RandomForestClassifier, \n",
    "                              AdaBoostClassifier, GradientBoostingClassifier)\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "min_max_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "model_tree = SelectFromModel(ExtraTreesClassifier(random_state=32), prefit=False)\n",
    "\n",
    "models = { \n",
    "    'GaussianNB':GaussianNB(),\n",
    "    #'ExtraTreesClassifier': ExtraTreesClassifier(),\n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'AdaBoostClassifier': AdaBoostClassifier(),\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier()#,\n",
    "    #'SVC': SVC()\n",
    "}\n",
    "\n",
    "params_s = { \n",
    "    'GaussianNB': {'GaussianNB__priors':[None,[0.124,0.876]]},\n",
    "    #'ExtraTreesClassifier': { 'ExtraTreesClassifier__n_estimators': [16, 32] },\n",
    "    'RandomForestClassifier': { 'RandomForestClassifier__n_estimators': [16, 32,50,100],\n",
    "                                'RandomForestClassifier__min_samples_split': [2,3,4],\n",
    "                                'RandomForestClassifier__max_features':[3,4,5]},                   \n",
    "    'AdaBoostClassifier':  { 'AdaBoostClassifier__n_estimators': [16, 32]},\n",
    "    'GradientBoostingClassifier': { 'GradientBoostingClassifier__n_estimators': [16, 32],\n",
    "                                    'GradientBoostingClassifier__learning_rate': [0.8, 1.0]}#,\n",
    "    #'SVC':[\n",
    "    #    {'SVC__kernel': ['linear'], 'SVC__C': [1, 10]},\n",
    "    #    {'SVC__kernel': ['rbf','linear'], 'SVC__C': [1, 10], 'SVC__gamma': ['auto', 0.001, 0.0001]}\n",
    "    #   ]\n",
    "}\n",
    "\n",
    "params_selector ={'selector__threshold':['mean','0.5*mean','1.4*mean'] }\n",
    "\n",
    "keys = models.keys()\n",
    "grid_searches = {}\n",
    "    \n",
    "preparation = [('scaler',min_max_scaler)]\n",
    "              #,('selector',model_tree)]\n",
    "\n",
    "def scorer_r_p(estimator, X_test, y_test):\n",
    "    y_pred = estimator.predict(X_test)\n",
    "    r_score = recall_score(y_test, y_pred)\n",
    "    p_score = precision_score(y_test, y_pred)\n",
    "#    f1_score = f1_score(y_test, y_pred)\n",
    "    if r_score<0.3 or p_score<0.3:\n",
    "        return 0    \n",
    "    return r_score + p_score\n",
    "\n",
    "#------------------------fit ------------------------\n",
    "for key in models.keys():\n",
    "    print(\"------Running GridSearchCV for %s.------\" % key)\n",
    "    model = models[key]\n",
    "    params = params_s[key]\n",
    "    #if isinstance(params_s[key],list):\n",
    "    #    params = [dict(param.items() + params_selector.items()) for param in params_s[key]]           \n",
    "    #elif isinstance(params_s[key],dict):\n",
    "    #    params = dict(params_s[key].items() + params_selector.items())\n",
    "    estimators = preparation+[(key,model)]\n",
    "    print estimators\n",
    "    pipe= Pipeline(estimators) \n",
    "    print pipe\n",
    "    gs = GridSearchCV(pipe, params, cv=3, n_jobs=1, verbose=1, scoring='f1', refit=True)\n",
    "    gs.fit(X_train,y_train)\n",
    "    grid_searches[key] = gs     \n",
    "\n",
    "#------------------scores summary-------------------------    \n",
    "def row(k,scores,params):\n",
    "    d = {\n",
    "        'estimators': k,\n",
    "        'mean_score': mean(scores),\n",
    "        'min_score': min(scores),\n",
    "        'max_score': max(scores),\n",
    "        'std_score': std(scores)\n",
    "    }\n",
    "    return pd.Series(dict(d.items() + params.items()))\n",
    "\n",
    "\n",
    "rows = [row(k, gs.cv_validation_scores,gs.parameters)\n",
    "       for k in keys \n",
    "           for gs in grid_searches[k].grid_scores_]\n",
    "df = pd.concat(rows, axis=1).T.sort_values('mean_score',ascending=False)\n",
    "columns = ['estimators','mean_score','min_score','max_score','std_score']\n",
    "columns = columns + [col for col in df.columns.values if col not in columns]\n",
    "print df[columns]\n",
    "\n",
    "#-----------------best classifier------------------\n",
    "#grid_searches['AdaBoostClassifier'].best_estimator_.steps[2][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
       " ('selector',\n",
       "  SelectFromModel(estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=10, n_jobs=1, oob_score=False, random_state=32,\n",
       "             verbose=0, warm_start=False),\n",
       "          prefit=False, threshold='0.5*mean')),\n",
       " ('AdaBoostClassifier',\n",
       "  AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "            learning_rate=1.0, n_estimators=32, random_state=None))]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_searches[df[columns].iloc[0,0]].best_estimator_.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'kernel': ('linear', 'rbf'), 'C': [1, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clf.best_score_\n",
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用 model_selection 中的GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy import mean,std\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "'''\n",
    "refit : boolean, default=True\n",
    "Refit the best estimator with the entire dataset. \n",
    "If “False”, it is impossible to make predictions using this GridSearchCV instance after fitting.\n",
    "'''\n",
    "\n",
    "\n",
    "class ModelsSelector(object):\n",
    "\t\"\"\"docstring for ClassName\"\"\"\n",
    "\tdef __init__(self, models, params):\n",
    "\t\tif not set(models.keys()).issubset(set(params.keys())):\n",
    "\t\t\tmiss_models =  set(models.keys()) - set(params.keys())\n",
    "\t\t\traise ValueError(\"Some models are missing parameters: %s .\" % miss_models)\n",
    "\t\tself.models = models\n",
    "\t\tself.params = params\n",
    "\t\tself.keys = models.keys()\n",
    "\t\tself.grid_select = {}\n",
    "\n",
    "\tdef fit(self, X, y, cv=3, scoring=None, refit=False, verbose=1, n_jobs=1):\n",
    "\t\tfor key in self.keys:\n",
    "\t\t\tprint (\"Running GridSelectCV for %s .\" % key)\n",
    "\t\t\tmodel = self.models[key]\n",
    "\t\t\tparams = self.params[key]\n",
    "\t\t\tgs_cv = GridSearchCV(model, param_grid=params, cv=cv, scoring=scoring,\n",
    "\t\t\t\t\t\t\t\tn_jobs=n_jobs, refit=refit, verbose=verbose)\n",
    "\t\t\tgs_cv.fit\n",
    "\t\t\tself.grid_select[key] = gs_cv\n",
    "\n",
    "\n",
    "\tdef score_summary(self,sort_by='mean_score'):\n",
    "\t\tevaluate_keys = ['mean_test_score','std_test_score','mean_train_score','std_train_score','params','rank_test_score']\n",
    "\t\tcv_result_dfs = []\n",
    "\t\tfor k in self.keys:\n",
    "\t\t\tcv_result_dict = {}\n",
    "\t\t\tfor gs_cv_result_k, gs_cv_result_v in self.grid_select[k].cv_results_.items():\n",
    "\t\t\t\t#cv_result_df = pd.DataFrame.from_dict(cv_results_,orient='columns')\n",
    "\t\t\t\tif gs_cv_result_k in evaluate_keys:\n",
    "\t\t\t\t\tcv_result_dict[gs_cv_result_k] = gs_cv_result_v\n",
    " \t\t\tcv_result_dict['estimator'] = [k]*len(self.grid_select[k].cv_results_['mean_test_score'])\n",
    " \t\t\tcv_result_df = pd.DataFrame.from_dict(cv_result_dict,orient='columns')\n",
    " \t\t\tcv_result_dfs.append(cv_result_df)\n",
    " #[mydict[x] for x in evaluate_keys]\n",
    " \t\tcv_results = pd.concat(cv_result_dfs)\n",
    " \t\treturn cv_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSelectCV for SVC .\n",
      "Running GridSelectCV for AdaBoostClassifier .\n",
      "Running GridSelectCV for GradientBoostingClassifier .\n",
      "Running GridSelectCV for ExtraTreesClassifier .\n",
      "Running GridSelectCV for RandomForestClassifier .\n"
     ]
    }
   ],
   "source": [
    "helper2 = ModelsSelector(models1, params1)\n",
    "helper2.fit(X_train_new,y_train,cv=3, scoring='f1', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'cv_results_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-fc648d9c5a77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhelper2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msort_by\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_score'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-006a71216cb8>\u001b[0m in \u001b[0;36mscore_summary\u001b[0;34m(self, sort_by)\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                         \u001b[0mcv_result_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                         \u001b[0;32mfor\u001b[0m \u001b[0mgs_cv_result_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgs_cv_result_v\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_select\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m                                 \u001b[0;31m#cv_result_df = pd.DataFrame.from_dict(cv_results_,orient='columns')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                                 \u001b[0;32mif\u001b[0m \u001b[0mgs_cv_result_k\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevaluate_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'cv_results_'"
     ]
    }
   ],
   "source": [
    "helper2.score_summary(sort_by='mean_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
