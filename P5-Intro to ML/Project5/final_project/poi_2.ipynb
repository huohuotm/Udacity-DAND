{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/weidian1/Documents/GitHub/Udacity-DAND/P5-Intro to ML/Project5/final_project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "#sys.path.append(\"../pylof-master/\")\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "\n",
    "### Task 1: Select what features you'll use.\n",
    "### features_list is a list of strings, each of which is a feature name.\n",
    "### The first feature must be \"poi\".\n",
    "#features_list = ['poi','salary',''] # You will need to use more features\n",
    "\n",
    "### Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of data points:  143\n",
      "Number of POI: 18, no. of non-POI: 125\n",
      "Number of features used:  21\n"
     ]
    }
   ],
   "source": [
    "# 异常值， 去掉total\n",
    "def remove_outerliers(data_dict,names):\n",
    "    for name in names:\n",
    "        data_dict.pop(name, 0)\n",
    "    return data_dict\n",
    "\n",
    "def dateset_summary(data_dic):\n",
    "    n_poi,n_non_poi = 0,0\n",
    "    for key in data_dict.keys():\n",
    "        if data_dict[key]['poi']==1:\n",
    "            n_poi+=1\n",
    "        else:\n",
    "            n_non_poi+=1        \n",
    "    print \"Total number of data points: \", len(data_dict)\n",
    "    print \"Number of POI: %d, no. of non-POI: %d\"% (n_poi, n_non_poi)\n",
    "    print \"Number of features used: \",len(data_dict['METTS MARK']) # randomly pick one name, get the number of features.\n",
    "\n",
    "outliers_names =  ['TOTAL', 'THE TRAVEL AGENCY IN THE PARK', 'LOCKHART EUGENE E']#['TOTAL']#,'LAVORATO JOHN J'\n",
    "\n",
    "data_dict = remove_outerliers(data_dict,outliers_names)\n",
    "dateset_summary(dateset_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "salary                        0\n",
      "to_messages                  57\n",
      "deferral_payments             0\n",
      "total_payments                0\n",
      "exercised_stock_options       0\n",
      "bonus                         0\n",
      "restricted_stock              0\n",
      "shared_receipt_with_poi      57\n",
      "restricted_stock_deferred     0\n",
      "total_stock_value             0\n",
      "expenses                      0\n",
      "loan_advances                 0\n",
      "from_messages                57\n",
      "other                         0\n",
      "from_this_person_to_poi      57\n",
      "poi                           0\n",
      "director_fees                 0\n",
      "deferred_income               0\n",
      "long_term_incentive           0\n",
      "email_address                32\n",
      "from_poi_to_this_person      57\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_df = pd.DataFrame.from_dict(data_dict,orient='index')\n",
    "\n",
    "financial_features = ['salary', 'deferral_payments', 'total_payments', 'loan_advances', 'bonus'\n",
    "                 , 'restricted_stock_deferred', 'deferred_income', 'total_stock_value', 'expenses'\n",
    "                 , 'exercised_stock_options', 'other', 'long_term_incentive', 'restricted_stock'\n",
    "                 , 'director_fees']\n",
    "email_fatures = ['to_messages','from_poi_to_this_person', 'from_messages', 'from_this_person_to_poi'\n",
    "                 , 'shared_receipt_with_poi']  # remove 'email_address'\n",
    "def NaNs_to_0s(col):\n",
    "    return [0 if ele=='NaN' else ele for ele in col]\n",
    "\n",
    "def NaNs_to_None(col):\n",
    "    return [None if ele=='NaN' else ele for ele in col]\n",
    "\n",
    "def count_NAN(col):\n",
    "    return sum(1 for ele in col if ele == 'NaN')\n",
    "\n",
    "data_df[financial_features] = data_df[financial_features].apply(NaNs_to_0s, axis=0)\n",
    "data_df['poi'] = data_df['poi'].astype(int)\n",
    "print data_df.apply(count_NAN, axis=0)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11bc7fdd0>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEaCAYAAAAsQ0GGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDw39+bI31sIyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11bcb1c10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "data_df.boxplot('bonus', by='poi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "make new feature \n",
    "1. 'email_features_miss': if email_features is missing. next step, missing email_features will be\n",
    "transformed to 0, which should by different from missing financial features.   \n",
    "2. poi_rate_to_messages = from_this_person_to_poi/to_messages  \n",
    "3. poi_rate_from_messages = from_poi_to_this_person/from_messages\n",
    "\n",
    "\"\"\"\n",
    "data_df['email_features_miss'] = data_df.apply(lambda x: 1 if x[\"to_messages\"]=='NaN' else 0, axis = 1)\n",
    "\n",
    "data_df['poi_rate_to_messages'] = data_df.apply(lambda x: 0 if x['from_this_person_to_poi']=='NaN' \\\n",
    "                                                else x['from_this_person_to_poi']*1.0/x['to_messages'], axis=1)\n",
    "\n",
    "data_df['poi_rate_from_messages'] = data_df.apply(lambda x: 0 if x['from_poi_to_this_person']=='NaN'\\\n",
    "                                                  else x['from_poi_to_this_person']*1.0/x['from_messages'], axis =1)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(143, 24)\n",
      "['salary' 'to_messages' 'deferral_payments' 'total_payments'\n",
      " 'exercised_stock_options' 'bonus' 'restricted_stock'\n",
      " 'shared_receipt_with_poi' 'restricted_stock_deferred' 'total_stock_value'\n",
      " 'expenses' 'loan_advances' 'from_messages' 'other'\n",
      " 'from_this_person_to_poi' 'poi' 'director_fees' 'deferred_income'\n",
      " 'long_term_incentive' 'email_address' 'from_poi_to_this_person'\n",
      " 'email_features_miss' 'poi_rate_to_messages' 'poi_rate_from_messages']\n"
     ]
    }
   ],
   "source": [
    "print data_df.shape#columns.values; 24个变量\n",
    "print data_df.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 这些新变量不要了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"create new features\n",
    "\"\"\"\n",
    "def get_new(col,p):\n",
    "    return (data_df[col].apply(abs)/(10**(p-1))%10).astype(int)\n",
    "def over_zero(ele):\n",
    "    if ele>0:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def add_new_features(df):\n",
    "    df[\"bonus_over_zero\"] = df['bonus'].apply(over_zero)\n",
    "    df[\"bonus_six\"] = get_new(\"bonus\",6)\n",
    "    df[\"bonus_seven\"] = get_new(\"bonus\",7)\n",
    "    \n",
    "    df[\"expenses_over_zero\"] = df[\"expenses\"].apply(over_zero)\n",
    "    df[\"expenses_five\"] = get_new(\"expenses\",5)\n",
    "    df[\"expenses_six\"] = get_new(\"expenses\",6)\n",
    "    \n",
    "    df[\"exercised_stock_options_over_zero\"] = df[\"exercised_stock_options\"].apply(over_zero)\n",
    "    df[\"exercised_stock_options_six\"] = get_new(\"exercised_stock_options\",6)\n",
    "    df[\"exercised_stock_options_seven\"] = get_new(\"exercised_stock_options\",7)\n",
    "    df[\"exercised_stock_options_eight\"] = get_new(\"exercised_stock_options\",8)\n",
    "    \n",
    "    df[\"salary_over_zero\"] = df[\"salary\"].apply(over_zero)\n",
    "    df[\"salary_six\"] = get_new(\"salary\",6)\n",
    "    df[\"salary_seven\"] = get_new(\"salary\",7)\n",
    "    \n",
    "    df[\"restricted_stock_over_zero\"] = df[\"restricted_stock\"].apply(over_zero)\n",
    "    df[\"restricted_stock_six\"] = get_new(\"restricted_stock\",6)\n",
    "    df[\"restricted_stock_seven\"] = get_new(\"restricted_stock\",7)\n",
    "    df[\"restricted_stock_eight\"] = get_new(\"restricted_stock\",8)\n",
    "    \n",
    "    df[\"deferred_income_over_zero\"] = df[\"deferred_income\"].apply(over_zero)\n",
    "    df[\"deferred_income_five\"] = get_new(\"deferred_income\",5)\n",
    "    df[\"deferred_income_six\"] = get_new(\"deferred_income\",6)\n",
    "    df[\"deferred_income_seven\"] = get_new(\"deferred_income\",7)\n",
    "    \n",
    "    df[\"other_over_zero\"] = df[\"other\"].apply(over_zero)\n",
    "    df[\"other_six\"] = get_new(\"other\",6)\n",
    "    df[\"other_seven\"] = get_new(\"other\",7)\n",
    "    df[\"other_eight\"] = get_new(\"other\",8)\n",
    "    return df\n",
    "\n",
    "data_df = add_new_features(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get mydata(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 full_columns_name: ['poi', 'salary', 'to_messages', 'deferral_payments', 'total_payments', 'exercised_stock_options', 'bonus', 'restricted_stock', 'shared_receipt_with_poi', 'restricted_stock_deferred', 'total_stock_value', 'expenses', 'loan_advances', 'from_messages', 'other', 'from_this_person_to_poi', 'director_fees', 'deferred_income', 'long_term_incentive', 'from_poi_to_this_person', 'email_features_miss', 'poi_rate_to_messages', 'poi_rate_from_messages']\n"
     ]
    }
   ],
   "source": [
    "features_full_list = list(data_df.columns.values)\n",
    "features_full_list.remove('email_address')\n",
    "features_full_list.remove('poi')\n",
    "features_full_list = ['poi'] +features_full_list\n",
    "data_full_dic = data_df.to_dict(orient='index')\n",
    "print (\"%d full_columns_name: %s\" % (len(features_full_list), features_full_list))\n",
    "\n",
    "#def get_train_test_dataset(my_dataset,features_list):\n",
    "#    #Extract features and labels from dataset for local testing\n",
    "#    data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "#    labels, features = targetFeatureSplit(data)\n",
    "#    # TODO: Shuffle the data\n",
    "#    from sklearn.utils import shuffle\n",
    "#    features, labels = shuffle(features, labels, random_state=1)\n",
    "#    \n",
    "#    # split train test dataset\n",
    "#    from sklearn.model_selection import train_test_split\n",
    "#    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "#    X_train = np.array(X_train)\n",
    "#    y_train = np.array(y_train)\n",
    "#    X_test = np.array(X_test)\n",
    "#    y_test = np.array(y_test)\n",
    "#    \n",
    "#    return X_train, X_test, y_train, y_test\n",
    "#    \n",
    "#X_train, X_test, y_train, y_test = get_train_test_dataset(data_full_dic,features_full_list)  \n",
    "    \n",
    "def get_features_labels(my_dataset,features_list):\n",
    "    #Extract features and labels from dataset for local testing\n",
    "    data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "    labels, features = targetFeatureSplit(data)\n",
    "    # TODO: Shuffle the data\n",
    "    from sklearn.utils import shuffle\n",
    "    features, labels = shuffle(features, labels, random_state=1)\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "    return features, labels\n",
    "\n",
    "def get_train_test_dataset(features, labels):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "  \n",
    "features, labels = get_features_labels(data_full_dic,features_full_list)\n",
    "X_train, X_test, y_train, y_test = get_train_test_dataset(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poi</th>\n",
       "      <th>loan_advances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FREVERT MARK A</th>\n",
       "      <td>0</td>\n",
       "      <td>2000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAY KENNETH L</th>\n",
       "      <td>1</td>\n",
       "      <td>81525000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PICKERING MARK R</th>\n",
       "      <td>0</td>\n",
       "      <td>400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  poi  loan_advances\n",
       "FREVERT MARK A      0        2000000\n",
       "LAY KENNETH L       1       81525000\n",
       "PICKERING MARK R    0         400000"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df[data_df['loan_advances']>0][['poi','loan_advances']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "min_max_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train_scaled = min_max_scaler.fit_transform(X_train)\n",
    "X_test_scaled = min_max_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## select features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "select important features \n",
    "\"\"\"\n",
    "def select_features(X_train,y_train,X_test, method='tree',k=None):\n",
    "    from sklearn.utils import shuffle\n",
    "    X_train, y_train = shuffle(X_train, y_train, random_state=0)\n",
    "    if method == 'tree':\n",
    "        \n",
    "        from sklearn.ensemble import ExtraTreesClassifier\n",
    "        from sklearn.feature_selection import SelectFromModel   \n",
    "\n",
    "        selection_tree = ExtraTreesClassifier(random_state=32)\n",
    "        selection_tree = selection_tree.fit(X_train, y_train)\n",
    "\n",
    "        model_tree = SelectFromModel(selection_tree, prefit=True)\n",
    "        X_train_new = model_tree.transform(X_train)\n",
    "        X_test_new = model_tree.transform(X_test)\n",
    "        \n",
    "        print \"shape of X_train: \", X_train.shape\n",
    "        print \"shape of X_train_new: \", X_train_new.shape    \n",
    "        return selection_tree,X_train_new,X_test_new\n",
    "    \n",
    "    elif method == 'kbest' and k:\n",
    "        from sklearn.feature_selection import SelectKBest\n",
    "        from sklearn.feature_selection import f_classif\n",
    "\n",
    "        selection_k= SelectKBest(f_classif, k=k).fit(X_train, y_train)\n",
    "        X_train_new = selection_k.transform(X_train)\n",
    "        X_test_new = selection_k.transform(X_test)\n",
    "        print \"shape of X_train: \", X_train.shape\n",
    "        print \"shape of X_train_new: \", X_train_new.shape   \n",
    "        return selection_k,X_train_new,X_test_new\n",
    "        \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#selection_tree,X_train_new,X_test_new = select_features(X_train_scaled,y_train,X_test_scaled)\n",
    "X_train_new,X_test_new = X_train_scaled,X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X_train:  (101, 22)\n",
      "shape of X_train_new:  (101, 10)\n"
     ]
    }
   ],
   "source": [
    "selection_k,X_train_new,X_test_new = select_features(X_train_scaled,y_train,X_test_scaled,method='kbest',k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def train_model(classifier,features_train,labels_train,features_test):\n",
    "    clf = classifier\n",
    "    clf.fit(features_train, labels_train)\n",
    "    labels_pred = clf.predict(features_test)\n",
    "    return clf,labels_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluation_metric(labels_test,labels_pred):\n",
    "    from sklearn.metrics import recall_score\n",
    "    from sklearn.metrics import precision_score\n",
    "    from sklearn.metrics import f1_score\n",
    "    \n",
    "    print \"recall_score: \",recall_score(y_test, labels_pred)\n",
    "    print \"precision_score: \",precision_score(labels_test, labels_pred)  \n",
    "    print \"f1_score: \",f1_score(labels_test, labels_pred)  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用tree 的到的features，建模，问题\n",
    "navie bayers 和 decision tree 完全反的;    \n",
    "SVM，randomforest 出现no TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_score:  0.444444444444\n",
      "precision_score:  0.5\n",
      "f1_score:  0.470588235294\n"
     ]
    }
   ],
   "source": [
    "# naive bayers\n",
    "clf_nb,y_pred_nb = train_model(GaussianNB(),X_train,y_train,X_test)\n",
    "evaluation_metric(y_test,y_pred_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_score:  0.666666666667\n",
      "precision_score:  0.214285714286\n",
      "f1_score:  0.324324324324\n"
     ]
    }
   ],
   "source": [
    "clf_nb,y_pred_nb = train_model(GaussianNB(),X_train_scaled,y_train,X_test_scaled)\n",
    "evaluation_metric(y_test,y_pred_nb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_score:  0.0\n",
      "precision_score:  0.0\n",
      "f1_score:  0.0\n"
     ]
    }
   ],
   "source": [
    "#svm\n",
    "clf_svm,y_pred_svm = train_model(SVC(),X_train_new,y_train,X_test_new)\n",
    "evaluation_metric(y_test,y_pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_score:  0.111111111111\n",
      "precision_score:  0.25\n",
      "f1_score:  0.153846153846\n"
     ]
    }
   ],
   "source": [
    "# decision tree\n",
    "clf_dtree,y_pred_stree = train_model(tree.DecisionTreeClassifier(),X_train_new,y_train,X_test_new)\n",
    "evaluation_metric(y_test,y_pred_stree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_score:  0.0\n",
      "precision_score:  0.0\n",
      "f1_score:  0.0\n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "\n",
    "clf_froest,y_pred_forest = train_model(RandomForestClassifier(n_estimators=10),X_train_new,y_train,X_test_new)\n",
    "evaluation_metric(y_test,y_pred_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kbest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_score:  0.666666666667\n",
      "precision_score:  0.285714285714\n",
      "f1_score:  0.4\n"
     ]
    }
   ],
   "source": [
    "# naive bayers\n",
    "clf_nb,y_pred_nb = train_model(GaussianNB(),X_train_new,y_train,X_test_new)\n",
    "evaluation_metric(y_test,y_pred_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_score:  0.0\n",
      "precision_score:  0.0\n",
      "f1_score:  0.0\n"
     ]
    }
   ],
   "source": [
    "#svm\n",
    "clf_svm,y_pred_svm = train_model(SVC(),X_train_new,y_train,X_test_new)\n",
    "evaluation_metric(y_test,y_pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_score:  0.0\n",
      "precision_score:  0.0\n",
      "f1_score:  0.0\n"
     ]
    }
   ],
   "source": [
    "# decision tree\n",
    "clf_dtree,y_pred_stree = train_model(tree.DecisionTreeClassifier(),X_train_new,y_train,X_test_new)\n",
    "evaluation_metric(y_test,y_pred_stree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_score:  0.0\n",
      "precision_score:  0.0\n",
      "f1_score:  0.0\n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "\n",
    "clf_froest,y_pred_forest = train_model(RandomForestClassifier(n_estimators=10),X_train_new,y_train,X_test_new)\n",
    "evaluation_metric(y_test,y_pred_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipiline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "estimators = [('reduce_dim', PCA()), ('clf', SVC())]\n",
    "pipe = Pipeline(estimators)\n",
    "pipe \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "params = dict(reduce_dim__n_components=[2, 5, 10],\n",
    "              clf__C=[0.1, 10, 100])\n",
    "grid_search = GridSearchCV(pipe, param_grid=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "params = dict(reduce_dim=[None, PCA(5), PCA(10)],\n",
    "              clf=[SVC(), LogisticRegression()],\n",
    "              clf__C=[0.1, 10, 100])\n",
    "grid_search = GridSearchCV(pipe, param_grid=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy import mean,std\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import (ExtraTreesClassifier, RandomForestClassifier, \n",
    "                              AdaBoostClassifier, GradientBoostingClassifier)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class EstimatorSelectionHelper:\n",
    "    def __init__(self, models, params):\n",
    "        if not set(models.keys()).issubset(set(params.keys())):\n",
    "            missing_params = list(set(models.keys()) - set(params.keys()))\n",
    "            raise ValueError(\"Some estimators are missing parameters: %s\" % missing_params)\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "        \n",
    "        min_max_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        model_tree = SelectFromModel(ExtraTreesClassifier(random_state=32), prefit=False)\n",
    "        \n",
    "        preparation = [#('scaler',min_max_scaler),\n",
    "                      ('selector',model_tree)]\n",
    "        self.params_selector ={'selector__threshold':['0.5*mean','0.8*mean','mean','1.2*mean','1.4*mean'] }\n",
    "        \n",
    "        self.preparation = preparation\n",
    "        self.scores_df = None\n",
    "\n",
    "    def fit(self, X, y, cv=3, n_jobs=1, verbose=1, scoring=None, refit=True):\n",
    "        for key in self.keys:\n",
    "            print(\"Running GridSearchCV for %s.\" % key)\n",
    "            model = self.models[key]\n",
    "            #params = self.params[key]\n",
    "            if isinstance(self.params[key],list):\n",
    "                params = [dict(param.items() + self.params_selector.items()) for param in self.params[key]]           \n",
    "            elif isinstance(self.params[key],dict):\n",
    "                params = dict(self.params[key].items() + self.params_selector.items())\n",
    "            preparation = self.preparation\n",
    "            pipe= Pipeline(preparation +[(key,model)])        \n",
    "            gs = GridSearchCV(pipe, params, cv=cv, n_jobs=n_jobs,verbose=verbose, scoring=scoring, refit=refit)\n",
    "            gs.fit(X,y)\n",
    "            self.grid_searches[key] = gs    \n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                 'estimator': key,\n",
    "                 'min_score': min(scores),\n",
    "                 'max_score': max(scores),\n",
    "                 'mean_score': mean(scores),\n",
    "                 'std_score': std(scores),\n",
    "            }\n",
    "            return pd.Series(dict(params.items() + d.items()))\n",
    "\n",
    "        rows = [row(k, gsc.cv_validation_scores, gsc.parameters) \n",
    "                     for k in self.keys\n",
    "                     for gsc in self.grid_searches[k].grid_scores_]\n",
    "        df = pd.concat(rows, axis=1).T.sort_values(by=[sort_by], ascending=False)\n",
    "\n",
    "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "        self.scores_df = df[columns]\n",
    "        return df[columns]\n",
    "    \n",
    "    def best_estimator_model(self):\n",
    "        if  isinstance(self.scores_df,pd.DataFrame):\n",
    "            model_name = self.scores_df.iloc[0,0]\n",
    "            best_estimator_ = self.grid_searches[model_name].best_estimator_\n",
    "            best_model = self.grid_searches[model_name].best_estimator_.steps[-1][-1]\n",
    "            return best_estimator_, best_model       \n",
    "        else:\n",
    "            raise ValueError('scores_df is None; run fit() and score_summary() first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for AdaBoostClassifier.\n",
      "Fitting 50 folds for each of 108 candidates, totalling 5400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weidian1/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/weidian1/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/weidian1/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    3.8s\n",
      "Process PoolWorker-63:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/weidian1/anaconda/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/weidian1/anaconda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/weidian1/anaconda/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "    task = get()\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-e6dfd57a8bb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mhelper1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEstimatorSelectionHelper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mhelper1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscorer_r_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-68-47c0c0d5ca6b>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cv, n_jobs, verbose, scoring, refit)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mpipe\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreparation\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrefit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_searches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/weidian1/anaconda/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m         \"\"\"\n\u001b[0;32m--> 829\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/weidian1/anaconda/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[1;32m    571\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m                                     error_score=self.error_score)\n\u001b[0;32m--> 573\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m                 for train, test in cv)\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/weidian1/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/weidian1/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "models1 = { \n",
    "    #'ExtraTreesClassifier': ExtraTreesClassifier(),\n",
    "    #'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'AdaBoostClassifier': AdaBoostClassifier(random_state=32)#,\n",
    "    #'GradientBoostingClassifier': GradientBoostingClassifier()\n",
    "    #'SVC': SVC()\n",
    "}\n",
    "\n",
    "params1 = { \n",
    "    'ExtraTreesClassifier': { 'ExtraTreesClassifier__n_estimators': [16, 32, 50, 100] },\n",
    "    'RandomForestClassifier': { 'RandomForestClassifier__n_estimators': [16, 32, 50, 100] },\n",
    "    'AdaBoostClassifier':  { 'AdaBoostClassifier__n_estimators': [16, 32, 50, 100]\n",
    "                             ,'AdaBoostClassifier__learning_rate':[0.5\n",
    "                                                                   # , 0.8\n",
    "                                                                   , 1.0\n",
    "                                                                   , 1.5\n",
    "                                                                   ,2\n",
    "                                                                   ,2.5\n",
    "                                                                   ,3\n",
    "                                                                   ,3.5\n",
    "                                                                   ,4\n",
    "                                                                   , 5]\n",
    "                           #  ,'AdaBoostClassifier__base_estimator':['DecisionTreeClassifier','GaussianNB']\n",
    "                           #  ,'AdaBoostClassifier__algorithm':['SAMME', 'SAMME.R']\n",
    "                           },\n",
    "    'GradientBoostingClassifier': { 'GradientBoostingClassifier__n_estimators': [16, 32, 50, 100]\n",
    "                                   , 'GradientBoostingClassifier__learning_rate': [0.5, 0.8, 1.0] }\n",
    "    #'SVC': [\n",
    "    #    {'SVC__kernel': ['linear'], 'SVC__C': [1, 10]},\n",
    "    #    {'SVC__kernel': ['rbf'], 'SVC__C': [1, 10], 'SVC__gamma': [0.001, 0.0001]},\n",
    "    #]\n",
    "}\n",
    "\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "def scorer_r_p(estimator, X_test, y_test):\n",
    "    y_pred = estimator.predict(X_test)\n",
    "    r_score = recall_score(y_test, y_pred)\n",
    "    p_score = precision_score(y_test, y_pred)\n",
    "#    f1_score = f1_score(y_test, y_pred)\n",
    "    if r_score<0.3 or p_score<0.3:\n",
    "        return 0\n",
    "    return  f1_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(labels, n_iter=50, test_size = 0.2, random_state=42)\n",
    "\n",
    "helper1 = EstimatorSelectionHelper(models1, params1)\n",
    "helper1.fit(features, labels,cv=sss, scoring=scorer_r_p, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model1:  AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=0.5, n_estimators=100, random_state=32)\n"
     ]
    }
   ],
   "source": [
    "scores_df1 = helper1.score_summary()\n",
    "#scores_df.iloc[0,0]\n",
    "best_estimator_1,best_model1 = helper1.best_estimator_model()\n",
    "print \"best model1: \",best_model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('selector', SelectFromModel(estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_l...hm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=0.5, n_estimators=100, random_state=32))])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimator_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>AdaBoostClassifier__learning_rate</th>\n",
       "      <th>AdaBoostClassifier__n_estimators</th>\n",
       "      <th>selector__threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.235825</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.27439</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.224322</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.282789</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.220937</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.2953</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.219548</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.265633</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5*mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.216231</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.273437</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.5*mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.253334</td>\n",
       "      <td>1.5</td>\n",
       "      <td>16</td>\n",
       "      <td>mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.210084</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.263864</td>\n",
       "      <td>1.5</td>\n",
       "      <td>100</td>\n",
       "      <td>mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.205163</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.256598</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5*mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.20475</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.257077</td>\n",
       "      <td>1.5</td>\n",
       "      <td>32</td>\n",
       "      <td>mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.193667</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.26847</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>1.4*mean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             estimator min_score mean_score max_score std_score  \\\n",
       "9   AdaBoostClassifier         0   0.235825       0.8   0.27439   \n",
       "18  AdaBoostClassifier         0   0.224322      0.75  0.282789   \n",
       "21  AdaBoostClassifier         0   0.220937  0.857143    0.2953   \n",
       "7   AdaBoostClassifier         0   0.219548      0.75  0.265633   \n",
       "37  AdaBoostClassifier         0   0.216231      0.75  0.273437   \n",
       "24  AdaBoostClassifier         0   0.210302      0.75  0.253334   \n",
       "33  AdaBoostClassifier         0   0.210084  0.666667  0.263864   \n",
       "19  AdaBoostClassifier         0   0.205163  0.666667  0.256598   \n",
       "27  AdaBoostClassifier         0    0.20475  0.666667  0.257077   \n",
       "11  AdaBoostClassifier         0   0.193667  0.857143   0.26847   \n",
       "\n",
       "   AdaBoostClassifier__learning_rate AdaBoostClassifier__n_estimators  \\\n",
       "9                                0.5                              100   \n",
       "18                                 1                               50   \n",
       "21                                 1                              100   \n",
       "7                                0.5                               50   \n",
       "37                                 2                               16   \n",
       "24                               1.5                               16   \n",
       "33                               1.5                              100   \n",
       "19                                 1                               50   \n",
       "27                               1.5                               32   \n",
       "11                               0.5                              100   \n",
       "\n",
       "   selector__threshold  \n",
       "9                 mean  \n",
       "18                mean  \n",
       "21                mean  \n",
       "7             0.5*mean  \n",
       "37            0.5*mean  \n",
       "24                mean  \n",
       "33                mean  \n",
       "19            0.5*mean  \n",
       "27                mean  \n",
       "11            1.4*mean  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>AdaBoostClassifier__learning_rate</th>\n",
       "      <th>AdaBoostClassifier__n_estimators</th>\n",
       "      <th>selector__threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.189382</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.234758</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.181643</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.247919</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.153104</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.238825</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.150564</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.235008</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.143971</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.245561</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.5*mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.13112</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.2359</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5*mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.126675</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.240379</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5*mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.121062</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.217005</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1.4*mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.119062</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.213943</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>1.4*mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.118485</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.21334</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.5*mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.103866</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.197572</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>1.4*mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0749841</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.17363</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>1.4*mean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             estimator min_score mean_score max_score std_score  \\\n",
       "24  AdaBoostClassifier         0   0.189382       0.6  0.234758   \n",
       "27  AdaBoostClassifier         0   0.181643  0.666667  0.247919   \n",
       "33  AdaBoostClassifier         0   0.153104  0.666667  0.238825   \n",
       "30  AdaBoostClassifier         0   0.150564  0.666667  0.235008   \n",
       "28  AdaBoostClassifier         0   0.143971  0.666667  0.245561   \n",
       "31  AdaBoostClassifier         0    0.13112  0.666667    0.2359   \n",
       "34  AdaBoostClassifier         0   0.126675  0.666667  0.240379   \n",
       "35  AdaBoostClassifier         0   0.121062  0.615385  0.217005   \n",
       "32  AdaBoostClassifier         0   0.119062  0.615385  0.213943   \n",
       "25  AdaBoostClassifier         0   0.118485       0.6   0.21334   \n",
       "29  AdaBoostClassifier         0   0.103866  0.571429  0.197572   \n",
       "26  AdaBoostClassifier         0  0.0749841  0.571429   0.17363   \n",
       "\n",
       "   AdaBoostClassifier__learning_rate AdaBoostClassifier__n_estimators  \\\n",
       "24                                 2                               16   \n",
       "27                                 2                               32   \n",
       "33                                 2                              100   \n",
       "30                                 2                               50   \n",
       "28                                 2                               32   \n",
       "31                                 2                               50   \n",
       "34                                 2                              100   \n",
       "35                                 2                              100   \n",
       "32                                 2                               50   \n",
       "25                                 2                               16   \n",
       "29                                 2                               32   \n",
       "26                                 2                               16   \n",
       "\n",
       "   selector__threshold  \n",
       "24                mean  \n",
       "27                mean  \n",
       "33                mean  \n",
       "30                mean  \n",
       "28            0.5*mean  \n",
       "31            0.5*mean  \n",
       "34            0.5*mean  \n",
       "35            1.4*mean  \n",
       "32            1.4*mean  \n",
       "25            0.5*mean  \n",
       "29            1.4*mean  \n",
       "26            1.4*mean  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df1[scores_df1['AdaBoostClassifier__learning_rate']==2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selector SelectFromModel(estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=10, n_jobs=1, oob_score=False, random_state=32,\n",
      "           verbose=0, warm_start=False),\n",
      "        prefit=False, threshold='mean')\n",
      "AdaBoostClassifier AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=2,\n",
      "          n_estimators=16, random_state=32)\n"
     ]
    }
   ],
   "source": [
    "for step in best_estimator_1.steps:\n",
    "    print step[0],step[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=10, n_jobs=1, oob_score=False, random_state=32,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector_forest = best_estimator_1.steps[1][-1].estimator_\n",
    "selector_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 16 (0.117440)\n",
      "2. feature 17 (0.112995)\n",
      "3. feature 5 (0.104677)\n",
      "4. feature 9 (0.067156)\n",
      "5. feature 0 (0.066105)\n",
      "6. feature 2 (0.054996)\n",
      "7. feature 21 (0.054970)\n",
      "8. feature 3 (0.052955)\n",
      "9. feature 6 (0.051453)\n",
      "10. feature 18 (0.048225)\n",
      "11. feature 7 (0.043556)\n",
      "12. feature 13 (0.039803)\n",
      "13. feature 4 (0.038056)\n",
      "14. feature 1 (0.034536)\n",
      "15. feature 12 (0.031553)\n",
      "16. feature 10 (0.026751)\n",
      "17. feature 11 (0.021461)\n",
      "18. feature 20 (0.017219)\n",
      "19. feature 14 (0.007846)\n",
      "20. feature 8 (0.004066)\n",
      "21. feature 19 (0.003613)\n",
      "22. feature 15 (0.000567)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEKCAYAAADpfBXhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1150d96d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "selector_forest.fit(X_train , y_train)\n",
    "importances = selector_forest.feature_importances_\n",
    "#std = np.std([tree.feature_importances_ for tree in forest.estimators_],axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X_train_scaled .shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X_train_scaled.shape[1]), importances[indices],color=\"r\")#, yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X_train_scaled.shape[1]), indices)\n",
    "plt.xlim([-1, X_train_scaled.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weidian1/anaconda/lib/python2.7/site-packages/sklearn/feature_selection/univariate_selection.py:113: UserWarning: Features [11] are constant.\n",
      "  UserWarning)\n",
      "/Users/weidian1/anaconda/lib/python2.7/site-packages/sklearn/feature_selection/univariate_selection.py:113: UserWarning: Features [11] are constant.\n",
      "  UserWarning)\n",
      "/Users/weidian1/anaconda/lib/python2.7/site-packages/sklearn/feature_selection/univariate_selection.py:113: UserWarning: Features [11] are constant.\n",
      "  UserWarning)\n",
      "/Users/weidian1/anaconda/lib/python2.7/site-packages/sklearn/feature_selection/univariate_selection.py:113: UserWarning: Features [11] are constant.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedShuffleSplit(labels=[ 0.  0. ...,  0.  0.], n_iter=50, test_size=0.2, random_state=42),\n",
       "       error_score='raise',\n",
       "       estimator=Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('selector', SelectKBest(k=6, score_func=<function f_classif at 0x113480938>)), ('classifier', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=32))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'classifier__learning_rate': [0.2, 0.3, 0.4, 0.5], 'classifier__n_estimators': [50, 80], 'selector__score_func': [<function chi2 at 0x113480a28>, <function f_classif at 0x113480938>]},\n",
       "       pre_dispatch='2*n_jobs', refit=True,\n",
       "       scoring=<function scorer_r_p at 0x117f861b8>, verbose=0)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier  \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest,chi2,f_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "\n",
    "def scorer_r_p(estimator, X_test, y_test):\n",
    "    y_pred = estimator.predict(X_test)\n",
    "    r_score = recall_score(y_test, y_pred, average='micro')\n",
    "    p_score = precision_score(y_test, y_pred, average='micro')\n",
    "    if r_score<0.3 or p_score<0.3:\n",
    "        return 0\n",
    "    return  f1_score(y_test, y_pred, average='micro')\n",
    "\n",
    "\n",
    "\n",
    "sss = StratifiedShuffleSplit(labels, n_iter=50, test_size = 0.2, random_state=42)\n",
    "\n",
    "#helper1 = EstimatorSelectionHelper(models1, params1)\n",
    "#helper1.fit(features, labels,cv=sss, scoring=scorer_r_p, n_jobs=-1)\n",
    "\n",
    "\n",
    "pipe = Pipeline([('scaler',MinMaxScaler(feature_range=(0,1))), \n",
    "                ('selector', SelectKBest(k=6)),\n",
    "                  ('classifier', AdaBoostClassifier(random_state=32))])\n",
    "param_grid = dict( selector__score_func=[chi2,f_classif],\n",
    "                  #selector__k=range(5,13),\n",
    "                 classifier__n_estimators=[50,80]#,100]\n",
    "                 ,classifier__learning_rate=[0.2,0.3,0.4,0.5]#,0.6,0.8,1]#,2,3,4]\n",
    "                 )\n",
    "\n",
    "clf_grid = GridSearchCV(pipe, param_grid, scoring=scorer_r_p, cv=sss, n_jobs=-1)\n",
    "clf_grid.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method GridSearchCV.get_params of GridSearchCV(cv=StratifiedShuffleSplit(labels=[ 0.  0. ...,  0.  0.], n_iter=50, test_size=0.2, random_state=42),\n",
       "       error_score='raise',\n",
       "       estimator=Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('selector', SelectKBest(k=6, score_func=<function f_classif at 0x113480938>)), ('classifier', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=32))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'classifier__learning_rate': [0.2, 0.3, 0.4, 0.5], 'classifier__n_estimators': [50, 80], 'selector__score_func': [<function chi2 at 0x113480a28>, <function f_classif at 0x113480938>]},\n",
       "       pre_dispatch='2*n_jobs', refit=True,\n",
       "       scoring=<function scorer_r_p at 0x117f861b8>, verbose=0)>"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_grid.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('selector', SelectKBest(k=6, score_func=<function chi2 at 0x113480a28>)), ('classifier', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=0.2, n_estimators=50, random_state=32))])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clf.grid_scores_\n",
    "clf_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6:\n",
    "Dump your classifier, dataset, and features_list so anyone can\n",
    "check your results. You do not need to change anything below, but make sure that the version of poi_id.py that you submit can be run on its own and generates the necessary .pkl files for validating your results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tester import dump_classifier_and_data\n",
    "#clf = GaussianNB()#best_estimator_\n",
    "#features_list = [features_full_list[1:][index] for index,importance in enumerate(importances) if importance>=1.4*mean(importances)]\n",
    "#features_list = ['poi']+features_list\n",
    "features_list = features_full_list\n",
    "my_dataset = data_full_dic\n",
    "\n",
    "#best_estimator_1.set_params(AdaBoostClassifier__n_estimators=50, AdaBoostClassifier__learning_rate=1) \n",
    "#clf = best_estimator_1\n",
    "clf = clf_grid.best_estimator_\n",
    "#clf = Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
    "#                      ('selector', SelectKBest(k=6, score_func=f_classif)),\n",
    "#                      ('classifier', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
    "#                                                        learning_rate=1, n_estimators=100, random_state=32))])\n",
    "\n",
    "dump_classifier_and_data(clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('selector', SelectFromModel(estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_l...rithm='SAMME.R', base_estimator=None, learning_rate=2,\n",
       "          n_estimators=16, random_state=32))])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best_estimator_1.steps\n",
    "best_estimator_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('selector', SelectFromModel(estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_l...rithm='SAMME.R', base_estimator=None, learning_rate=2,\n",
       "          n_estimators=50, random_state=32))])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimator_1.set_params(AdaBoostClassifier__n_estimators=50) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('selector', SelectKBest(k=6, score_func=<function chi2 at 0x113480a28>)), ('classifier', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.5, n_estimators=50, random_state=32))])\n",
      "\tAccuracy: 0.83567\tPrecision: 0.35675\tRecall: 0.28950\tF1: 0.31962\tF2: 0.30084\n",
      "\tTotal predictions: 15000\tTrue positives:  579\tFalse positives: 1044\tFalse negatives: 1421\tTrue negatives: 11956\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/pickle\n",
    "\n",
    "\"\"\" a basic script for importing student's POI identifier,\n",
    "    and checking the results that they get from it \n",
    " \n",
    "    requires that the algorithm, dataset, and features list\n",
    "    be written to my_classifier.pkl, my_dataset.pkl, and\n",
    "    my_feature_list.pkl, respectively\n",
    "\n",
    "    that process should happen at the end of poi_id.py\n",
    "\"\"\"\n",
    "\n",
    "import pickle\n",
    "import sys\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "sys.path.append(\"../tools/\")\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "\n",
    "PERF_FORMAT_STRING = \"\\\n",
    "\\tAccuracy: {:>0.{display_precision}f}\\tPrecision: {:>0.{display_precision}f}\\t\\\n",
    "Recall: {:>0.{display_precision}f}\\tF1: {:>0.{display_precision}f}\\tF2: {:>0.{display_precision}f}\"\n",
    "RESULTS_FORMAT_STRING = \"\\tTotal predictions: {:4d}\\tTrue positives: {:4d}\\tFalse positives: {:4d}\\\n",
    "\\tFalse negatives: {:4d}\\tTrue negatives: {:4d}\"\n",
    "\n",
    "def test_classifier(clf, dataset, feature_list, folds = 1000):\n",
    "    data = featureFormat(dataset, feature_list, sort_keys = True)\n",
    "    labels, features = targetFeatureSplit(data)\n",
    "    cv = StratifiedShuffleSplit(labels, folds, random_state = 42)\n",
    "    true_negatives = 0\n",
    "    false_negatives = 0\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    for train_idx, test_idx in cv: \n",
    "        features_train = []\n",
    "        features_test  = []\n",
    "        labels_train   = []\n",
    "        labels_test    = []\n",
    "        for ii in train_idx:\n",
    "            features_train.append( features[ii] )\n",
    "            labels_train.append( labels[ii] )\n",
    "        for jj in test_idx:\n",
    "            features_test.append( features[jj] )\n",
    "            labels_test.append( labels[jj] )\n",
    "\n",
    "        ### fit the classifier using training set, and test on test set\n",
    "\n",
    "        clf.fit(features_train, list(labels_train))\n",
    "        predictions = clf.predict(features_test)\n",
    "        for prediction, truth in zip(predictions, labels_test):\n",
    "            if prediction == 0 and truth == 0:\n",
    "                true_negatives += 1\n",
    "            elif prediction == 0 and truth == 1:\n",
    "                false_negatives += 1\n",
    "            elif prediction == 1 and truth == 0:\n",
    "                false_positives += 1\n",
    "            elif prediction == 1 and truth == 1:\n",
    "                true_positives += 1\n",
    "            else:\n",
    "                print \"Warning: Found a predicted label not == 0 or 1.\"\n",
    "                print \"All predictions should take value 0 or 1.\"\n",
    "                print \"Evaluating performance for processed predictions:\"\n",
    "                break\n",
    "    try:\n",
    "        total_predictions = true_negatives + false_negatives + false_positives + true_positives\n",
    "        accuracy = 1.0*(true_positives + true_negatives)/total_predictions\n",
    "        precision = 1.0*true_positives/(true_positives+false_positives)\n",
    "        recall = 1.0*true_positives/(true_positives+false_negatives)\n",
    "        f1 = 2.0 * true_positives/(2*true_positives + false_positives+false_negatives)\n",
    "        f2 = (1+2.0*2.0) * precision*recall/(4*precision + recall)\n",
    "        print clf\n",
    "        print PERF_FORMAT_STRING.format(accuracy, precision, recall, f1, f2, display_precision = 5)\n",
    "        print RESULTS_FORMAT_STRING.format(total_predictions, true_positives, false_positives, false_negatives, true_negatives)\n",
    "        print \"\"\n",
    "    except:\n",
    "        print \"Got a divide by zero when trying out:\", clf\n",
    "        print \"Precision or recall may be undefined due to a lack of true positive predicitons.\"\n",
    "\n",
    "\n",
    "clf=Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
    "                    ('selector', SelectKBest(k=6, score_func=chi2)),\n",
    "                    ('classifier', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
    "                                                      learning_rate=1.5, n_estimators=50, random_state=32))])\n",
    "test_classifier(clf, data_full_dic, features_full_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('selector', SelectKBest(k=6, score_func=<function chi2 at 0x113480a28>)), ('classifier', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.5, n_estimators=100, random_state=32))])\n",
      "\tAccuracy: 0.83547\tPrecision: 0.35038\tRecall: 0.27400\tF1: 0.30752\tF2: 0.28649\n",
      "\tTotal predictions: 15000\tTrue positives:  548\tFalse positives: 1016\tFalse negatives: 1452\tTrue negatives: 11984\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf=Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
    "                    ('selector', SelectKBest(k=6, score_func=chi2)),\n",
    "                    ('classifier', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
    "                                                      learning_rate=1.5, n_estimators=100, random_state=32))])\n",
    "test_classifier(clf, data_full_dic, features_full_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('selector', SelectKBest(k=6, score_func=<function f_classif at 0x113480938>)), ('classifier', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.5, n_estimators=100, random_state=32))])\n",
      "\tAccuracy: 0.82413\tPrecision: 0.29887\tRecall: 0.23700\tF1: 0.26436\tF2: 0.24724\n",
      "\tTotal predictions: 15000\tTrue positives:  474\tFalse positives: 1112\tFalse negatives: 1526\tTrue negatives: 11888\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf=Pipeline(steps=[#('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
    "                    ('selector', SelectKBest(k=6, score_func=f_classif)),\n",
    "                    ('classifier', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
    "                                                      learning_rate=1.5, n_estimators=100, random_state=32))])\n",
    "test_classifier(clf, data_full_dic, features_full_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf=Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
    "                    ('selector', SelectKBest(k=6, score_func=chi2)),\n",
    "                    ('classifier', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
    "                                                      learning_rate=1, n_estimators=50, random_state=32))])\n",
    "test_classifier(clf, data_full_dic, features_full_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf=Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
    "                    ('selector', SelectKBest(k=6, score_func=chi2)),\n",
    "                    ('classifier', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
    "                                                      learning_rate=1, n_estimators=100, random_state=32))])\n",
    "test_classifier(clf, data_full_dic, features_full_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf=Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
    "                    ('selector', SelectKBest(k=6, score_func=chi2)),\n",
    "                    ('classifier', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
    "                                                      learning_rate=1, n_estimators=50, random_state=32))])\n",
    "test_classifier(clf, data_full_dic, features_full_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('selector', SelectKBest(k=6, score_func=<function chi2 at 0x113480a28>)), ('classifier', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.8, n_estimators=50, random_state=32))])\n",
      "\tAccuracy: 0.83280\tPrecision: 0.34340\tRecall: 0.27850\tF1: 0.30756\tF2: 0.28944\n",
      "\tTotal predictions: 15000\tTrue positives:  557\tFalse positives: 1065\tFalse negatives: 1443\tTrue negatives: 11935\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf=Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
    "                    ('selector', SelectKBest(k=6, score_func=chi2)),\n",
    "                    ('classifier', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
    "                                                      learning_rate=1.8, n_estimators=50, random_state=32))])\n",
    "test_classifier(clf, data_full_dic, features_full_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf=Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
    "                    ('selector', SelectKBest(k=6, score_func=chi2)),\n",
    "                    ('classifier', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
    "                                                      learning_rate=1.8, n_estimators=100, random_state=32))])\n",
    "test_classifier(clf, data_full_dic, features_full_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('selector', SelectKBest(k=6, score_func=<function chi2 at 0x113480a28>)), ('classifier', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.2, n_estimators=50, random_state=32))])\n",
      "\tAccuracy: 0.84040\tPrecision: 0.37073\tRecall: 0.28250\tF1: 0.32066\tF2: 0.29662\n",
      "\tTotal predictions: 15000\tTrue positives:  565\tFalse positives:  959\tFalse negatives: 1435\tTrue negatives: 12041\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf=Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
    "                    ('selector', SelectKBest(k=6, score_func=chi2)),\n",
    "                    ('classifier', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
    "                                                      learning_rate=1.2, n_estimators=50, random_state=32))])\n",
    "test_classifier(clf, data_full_dic, features_full_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('selector', SelectKBest(k=6, score_func=<function chi2 at 0x113480a28>)), ('classifier', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.2, n_estimators=30, random_state=32))])\n",
      "\tAccuracy: 0.83780\tPrecision: 0.35987\tRecall: 0.27800\tF1: 0.31368\tF2: 0.29125\n",
      "\tTotal predictions: 15000\tTrue positives:  556\tFalse positives:  989\tFalse negatives: 1444\tTrue negatives: 12011\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf=Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
    "                    ('selector', SelectKBest(k=6, score_func=chi2)),\n",
    "                    ('classifier', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
    "                                                      learning_rate=1.2, n_estimators=30, random_state=32))])\n",
    "test_classifier(clf, data_full_dic, features_full_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf=Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
    "                    ('selector', SelectKBest(k=6, score_func=chi2)),\n",
    "                    ('classifier', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
    "                                                      learning_rate=1.2, n_estimators=30, random_state=32))])\n",
    "test_classifier(clf, data_full_dic, features_full_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('selector', SelectKBest(k=6, score_func=<function chi2 at 0x113480a28>)), ('classifier', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.2, n_estimators=100, random_state=32))])\n",
      "\tAccuracy: 0.83740\tPrecision: 0.35569\tRecall: 0.27050\tF1: 0.30730\tF2: 0.28411\n",
      "\tTotal predictions: 15000\tTrue positives:  541\tFalse positives:  980\tFalse negatives: 1459\tTrue negatives: 12020\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf=Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
    "                    ('selector', SelectKBest(k=6, score_func=chi2)),\n",
    "                    ('classifier', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
    "                                                      learning_rate=1.2, n_estimators=100, random_state=32))])\n",
    "test_classifier(clf, data_full_dic, features_full_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.022727272727272724"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Running GridSearchCV for GaussianNB.------\n",
      "[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('selector', SelectFromModel(estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=10, n_jobs=1, oob_score=False, random_state=32,\n",
      "           verbose=0, warm_start=False),\n",
      "        prefit=False, threshold=None)), ('GaussianNB', GaussianNB(priors=None))]\n",
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('selector', SelectFromModel(estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_split=1e-07, min_samples_le... warm_start=False),\n",
      "        prefit=False, threshold=None)), ('GaussianNB', GaussianNB(priors=None))])\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Running GridSearchCV for AdaBoostClassifier.------\n",
      "[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('selector', SelectFromModel(estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=10, n_jobs=1, oob_score=False, random_state=32,\n",
      "           verbose=0, warm_start=False),\n",
      "        prefit=False, threshold=None)), ('AdaBoostClassifier', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None))]\n",
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('selector', SelectFromModel(estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_split=1e-07, min_samples_le...m='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None))])\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:    2.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Running GridSearchCV for GradientBoostingClassifier.------\n",
      "[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('selector', SelectFromModel(estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=10, n_jobs=1, oob_score=False, random_state=32,\n",
      "           verbose=0, warm_start=False),\n",
      "        prefit=False, threshold=None)), ('GradientBoostingClassifier', GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=None,\n",
      "              subsample=1.0, verbose=0, warm_start=False))]\n",
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('selector', SelectFromModel(estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_split=1e-07, min_samples_le...=100, presort='auto', random_state=None,\n",
      "              subsample=1.0, verbose=0, warm_start=False))])\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:    2.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Running GridSearchCV for RandomForestClassifier.------\n",
      "[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('selector', SelectFromModel(estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=10, n_jobs=1, oob_score=False, random_state=32,\n",
      "           verbose=0, warm_start=False),\n",
      "        prefit=False, threshold=None)), ('RandomForestClassifier', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False))]\n",
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('selector', SelectFromModel(estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_split=1e-07, min_samples_le...imators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False))])\n",
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weidian1/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max_features must be in (0, n_features]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-44de309128bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0mgrid_searches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/weidian1/anaconda/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m         \"\"\"\n\u001b[0;32m--> 829\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/weidian1/anaconda/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[1;32m    571\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m                                     error_score=self.error_score)\n\u001b[0;32m--> 573\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m                 for train, test in cv)\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/weidian1/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/weidian1/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/weidian1/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/weidian1/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/weidian1/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/weidian1/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/weidian1/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, error_score)\u001b[0m\n\u001b[1;32m   1663\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1664\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1665\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/weidian1/anaconda/lib/python2.7/site-packages/sklearn/pipeline.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/weidian1/anaconda/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    324\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 326\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/weidian1/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/weidian1/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/weidian1/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/weidian1/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/weidian1/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/weidian1/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/weidian1/anaconda/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/weidian1/anaconda/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    740\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/weidian1/anaconda/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"max_depth must be greater than zero. \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmax_features\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"max_features must be in (0, n_features]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_leaf_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntegral\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             raise ValueError(\"max_leaf_nodes must be integral number but was \"\n",
      "\u001b[0;31mValueError\u001b[0m: max_features must be in (0, n_features]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from numpy import mean,std\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import (ExtraTreesClassifier, RandomForestClassifier, \n",
    "                              AdaBoostClassifier, GradientBoostingClassifier)\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "min_max_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "model_tree = SelectFromModel(ExtraTreesClassifier(random_state=32), prefit=False)\n",
    "\n",
    "models = { \n",
    "    'GaussianNB':GaussianNB(),\n",
    "    #'ExtraTreesClassifier': ExtraTreesClassifier(),\n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'AdaBoostClassifier': AdaBoostClassifier(),\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier()#,\n",
    "    #'SVC': SVC()\n",
    "}\n",
    "\n",
    "params_s = { \n",
    "    'GaussianNB': {'GaussianNB__priors':[None,[0.124,0.876]]},\n",
    "    #'ExtraTreesClassifier': { 'ExtraTreesClassifier__n_estimators': [16, 32] },\n",
    "    'RandomForestClassifier': { 'RandomForestClassifier__n_estimators': [16, 32,50,100],\n",
    "                                'RandomForestClassifier__min_samples_split': [2,3,4],\n",
    "                                'RandomForestClassifier__max_features':[3,4,5]},                   \n",
    "    'AdaBoostClassifier':  { 'AdaBoostClassifier__n_estimators': [16, 32]},\n",
    "    'GradientBoostingClassifier': { 'GradientBoostingClassifier__n_estimators': [16, 32],\n",
    "                                    'GradientBoostingClassifier__learning_rate': [0.8, 1.0]}#,\n",
    "    #'SVC':[\n",
    "    #    {'SVC__kernel': ['linear'], 'SVC__C': [1, 10]},\n",
    "    #    {'SVC__kernel': ['rbf','linear'], 'SVC__C': [1, 10], 'SVC__gamma': ['auto', 0.001, 0.0001]}\n",
    "    #   ]\n",
    "}\n",
    "\n",
    "params_selector ={'selector__threshold':['mean','0.5*mean','1.4*mean'] }\n",
    "\n",
    "keys = models.keys()\n",
    "grid_searches = {}\n",
    "    \n",
    "preparation = [('scaler',min_max_scaler)\n",
    "              ,('selector',model_tree)]\n",
    "\n",
    "def scorer_r_p(estimator, X_test, y_test):\n",
    "    y_pred = estimator.predict(X_test)\n",
    "    r_score = recall_score(y_test, y_pred)\n",
    "    p_score = precision_score(y_test, y_pred)\n",
    "#    f1_score = f1_score(y_test, y_pred)\n",
    "    if r_score<0.3 or p_score<0.3:\n",
    "        return 0    \n",
    "    return r_score + p_score\n",
    "\n",
    "#------------------------fit ------------------------\n",
    "for key in models.keys():\n",
    "    print(\"------Running GridSearchCV for %s.------\" % key)\n",
    "    model = models[key]\n",
    "    params = params_s[key]\n",
    "    if isinstance(params_s[key],list):\n",
    "        params = [dict(param.items() + params_selector.items()) for param in params_s[key]]           \n",
    "    elif isinstance(params_s[key],dict):\n",
    "        params = dict(params_s[key].items() + params_selector.items())\n",
    "    estimators = preparation+[(key,model)]\n",
    "    print estimators\n",
    "    pipe= Pipeline(estimators) \n",
    "    print pipe\n",
    "    gs = GridSearchCV(pipe, params, cv=3, n_jobs=1, verbose=1, scoring='f1', refit=True)\n",
    "    gs.fit(X_train,y_train)\n",
    "    grid_searches[key] = gs     \n",
    "\n",
    "#------------------scores summary-------------------------    \n",
    "def row(k,scores,params):\n",
    "    d = {\n",
    "        'estimators': k,\n",
    "        'mean_score': mean(scores),\n",
    "        'min_score': min(scores),\n",
    "        'max_score': max(scores),\n",
    "        'std_score': std(scores)\n",
    "    }\n",
    "    return pd.Series(dict(d.items() + params.items()))\n",
    "\n",
    "\n",
    "rows = [row(k, gs.cv_validation_scores,gs.parameters)\n",
    "       for k in keys \n",
    "           for gs in grid_searches[k].grid_scores_]\n",
    "df = pd.concat(rows, axis=1).T.sort_values('mean_score',ascending=False)\n",
    "columns = ['estimators','mean_score','min_score','max_score','std_score']\n",
    "columns = columns + [col for col in df.columns.values if col not in columns]\n",
    "print df[columns]\n",
    "\n",
    "#-----------------best classifier------------------\n",
    "#grid_searches['AdaBoostClassifier'].best_estimator_.steps[2][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
       " ('selector',\n",
       "  SelectFromModel(estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=10, n_jobs=1, oob_score=False, random_state=32,\n",
       "             verbose=0, warm_start=False),\n",
       "          prefit=False, threshold='0.5*mean')),\n",
       " ('AdaBoostClassifier',\n",
       "  AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "            learning_rate=1.0, n_estimators=32, random_state=None))]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_searches[df[columns].iloc[0,0]].best_estimator_.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'kernel': ('linear', 'rbf'), 'C': [1, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clf.best_score_\n",
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用 model_selection 中的GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy import mean,std\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "'''\n",
    "refit : boolean, default=True\n",
    "Refit the best estimator with the entire dataset. \n",
    "If “False”, it is impossible to make predictions using this GridSearchCV instance after fitting.\n",
    "'''\n",
    "\n",
    "\n",
    "class ModelsSelector(object):\n",
    "\t\"\"\"docstring for ClassName\"\"\"\n",
    "\tdef __init__(self, models, params):\n",
    "\t\tif not set(models.keys()).issubset(set(params.keys())):\n",
    "\t\t\tmiss_models =  set(models.keys()) - set(params.keys())\n",
    "\t\t\traise ValueError(\"Some models are missing parameters: %s .\" % miss_models)\n",
    "\t\tself.models = models\n",
    "\t\tself.params = params\n",
    "\t\tself.keys = models.keys()\n",
    "\t\tself.grid_select = {}\n",
    "\n",
    "\tdef fit(self, X, y, cv=3, scoring=None, refit=False, verbose=1, n_jobs=1):\n",
    "\t\tfor key in self.keys:\n",
    "\t\t\tprint (\"Running GridSelectCV for %s .\" % key)\n",
    "\t\t\tmodel = self.models[key]\n",
    "\t\t\tparams = self.params[key]\n",
    "\t\t\tgs_cv = GridSearchCV(model, param_grid=params, cv=cv, scoring=scoring,\n",
    "\t\t\t\t\t\t\t\tn_jobs=n_jobs, refit=refit, verbose=verbose)\n",
    "\t\t\tgs_cv.fit\n",
    "\t\t\tself.grid_select[key] = gs_cv\n",
    "\n",
    "\n",
    "\tdef score_summary(self,sort_by='mean_score'):\n",
    "\t\tevaluate_keys = ['mean_test_score','std_test_score','mean_train_score','std_train_score','params','rank_test_score']\n",
    "\t\tcv_result_dfs = []\n",
    "\t\tfor k in self.keys:\n",
    "\t\t\tcv_result_dict = {}\n",
    "\t\t\tfor gs_cv_result_k, gs_cv_result_v in self.grid_select[k].cv_results_.items():\n",
    "\t\t\t\t#cv_result_df = pd.DataFrame.from_dict(cv_results_,orient='columns')\n",
    "\t\t\t\tif gs_cv_result_k in evaluate_keys:\n",
    "\t\t\t\t\tcv_result_dict[gs_cv_result_k] = gs_cv_result_v\n",
    " \t\t\tcv_result_dict['estimator'] = [k]*len(self.grid_select[k].cv_results_['mean_test_score'])\n",
    " \t\t\tcv_result_df = pd.DataFrame.from_dict(cv_result_dict,orient='columns')\n",
    " \t\t\tcv_result_dfs.append(cv_result_df)\n",
    " #[mydict[x] for x in evaluate_keys]\n",
    " \t\tcv_results = pd.concat(cv_result_dfs)\n",
    " \t\treturn cv_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSelectCV for SVC .\n",
      "Running GridSelectCV for AdaBoostClassifier .\n",
      "Running GridSelectCV for GradientBoostingClassifier .\n",
      "Running GridSelectCV for ExtraTreesClassifier .\n",
      "Running GridSelectCV for RandomForestClassifier .\n"
     ]
    }
   ],
   "source": [
    "helper2 = ModelsSelector(models1, params1)\n",
    "helper2.fit(X_train_new,y_train,cv=3, scoring='f1', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'cv_results_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-fc648d9c5a77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhelper2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msort_by\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_score'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-006a71216cb8>\u001b[0m in \u001b[0;36mscore_summary\u001b[0;34m(self, sort_by)\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                         \u001b[0mcv_result_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                         \u001b[0;32mfor\u001b[0m \u001b[0mgs_cv_result_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgs_cv_result_v\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_select\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m                                 \u001b[0;31m#cv_result_df = pd.DataFrame.from_dict(cv_results_,orient='columns')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                                 \u001b[0;32mif\u001b[0m \u001b[0mgs_cv_result_k\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevaluate_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'cv_results_'"
     ]
    }
   ],
   "source": [
    "helper2.score_summary(sort_by='mean_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
